"""
ç®€åŒ–çš„æµ‹è¯•åº”ç”¨
"""
from fastapi import FastAPI
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import json
import os
from datetime import datetime

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="è‡ªåŠ¨å‡è´ŸAIåº”ç”¨æ¶æ„",
    version="1.0.0",
    description="è‡ªåŠ¨å‡è´ŸAIåº”ç”¨æ¶æ„ - ç®€åŒ–æµ‹è¯•ç‰ˆæœ¬"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æº
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰æ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰å¤´éƒ¨
)

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "æ¬¢è¿ä½¿ç”¨è‡ªåŠ¨å‡è´ŸAIåº”ç”¨æ¶æ„ï¼",
        "version": "1.0.0",
        "status": "running"
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "message": "æœåŠ¡è¿è¡Œæ­£å¸¸"
    }

@app.get("/api/v1/projects")
async def get_projects():
    """è·å–é¡¹ç›®åˆ—è¡¨ï¼ˆçœŸå®æ•°æ®ï¼‰"""
    import json
    import os
    
    try:
        # è¯»å–çœŸå®æ•°æ®åº“æ–‡ä»¶
        db_path = "industry_standard_database_extended.json"
        if os.path.exists(db_path):
            with open(db_path, 'r', encoding='utf-8') as f:
                db_data = json.load(f)
            
            projects = db_data.get('projects', [])
            # æ·»åŠ è¿›åº¦ä¿¡æ¯
            for project in projects:
                project_id = project.get('project_id')
                if project_id in db_data.get('project_metrics', {}):
                    metrics = db_data['project_metrics'][project_id]
                    project['progress'] = metrics.get('progress_percentage', 0)
                else:
                    project['progress'] = 0
            
            return {
                "code": 200,
                "message": "è·å–é¡¹ç›®åˆ—è¡¨æˆåŠŸ",
                "data": projects
            }
        else:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›é»˜è®¤æ•°æ®
            return {
                "code": 200,
                "message": "è·å–é¡¹ç›®åˆ—è¡¨æˆåŠŸ",
                "data": [
                    {
                        "project_id": "PRJ-001",
                        "project_name": "æµ‹è¯•é¡¹ç›®1",
                        "description": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é¡¹ç›®",
                        "status": "è¿›è¡Œä¸­",
                        "progress": 75.0
                    }
                ]
            }
    except Exception as e:
        return {
            "code": 500,
            "message": f"è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {str(e)}",
            "data": []
        }

@app.get("/api/v1/tasks")
async def get_tasks():
    """è·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆçœŸå®æ•°æ®ï¼‰"""
    import json
    import os
    
    try:
        # è¯»å–çœŸå®æ•°æ®åº“æ–‡ä»¶
        db_path = "industry_standard_database_extended.json"
        if os.path.exists(db_path):
            with open(db_path, 'r', encoding='utf-8') as f:
                db_data = json.load(f)
            
            tasks = db_data.get('tasks', [])
            # æ·»åŠ è¿›åº¦ä¿¡æ¯
            for task in tasks:
                task['progress'] = task.get('progress_percentage', 0)
            
            return {
                "code": 200,
                "message": "è·å–ä»»åŠ¡åˆ—è¡¨æˆåŠŸ",
                "data": tasks
            }
        else:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›é»˜è®¤æ•°æ®
            return {
                "code": 200,
                "message": "è·å–ä»»åŠ¡åˆ—è¡¨æˆåŠŸ",
                "data": [
                    {
                        "task_id": "TASK-001",
                        "task_name": "éœ€æ±‚åˆ†æ",
                        "status": "å·²å®Œæˆ",
                        "priority": "é«˜",
                        "progress": 100.0
                    }
                ]
            }
    except Exception as e:
        return {
            "code": 500,
            "message": f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}",
            "data": []
        }

@app.get("/api/v1/auto-reduce/task-capture/meeting")
async def extract_tasks_from_meeting():
    """ä»ä¼šè®®çºªè¦æå–ä»»åŠ¡ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    return {
        "code": 200,
        "message": "ä»»åŠ¡æå–æˆåŠŸ",
        "data": {
            "count": 2,
            "tasks": [
                {
                    "task_id": "TASK-AUTO-001",
                    "task_name": "å®Œæˆç”¨æˆ·è®¤è¯æ¨¡å—",
                    "status": "å¾…å¼€å§‹",
                    "extracted_from": "ä¼šè®®çºªè¦"
                },
                {
                    "task_id": "TASK-AUTO-002", 
                    "task_name": "è®¾è®¡æ•°æ®åº“ç»“æ„",
                    "status": "å¾…å¼€å§‹",
                    "extracted_from": "ä¼šè®®çºªè¦"
                }
            ]
        }
    }

@app.get("/api/v1/auto-reduce/progress-summary/daily/{project_id}")
async def get_daily_progress_summary(project_id: str):
    """è·å–æ—¥æŠ¥ï¼ˆçœŸå®æ•°æ®ï¼‰"""
    import json
    import os
    from datetime import datetime
    
    try:
        # è¯»å–çœŸå®æ•°æ®åº“æ–‡ä»¶
        db_path = "industry_standard_database_extended.json"
        if os.path.exists(db_path):
            with open(db_path, 'r', encoding='utf-8') as f:
                db_data = json.load(f)
            
            # æŸ¥æ‰¾é¡¹ç›®ä¿¡æ¯
            project = None
            for p in db_data.get('projects', []):
                if p.get('project_id') == project_id:
                    project = p
                    break
            
            if not project:
                return {
                    "code": 404,
                    "message": f"é¡¹ç›® {project_id} ä¸å­˜åœ¨",
                    "data": None
                }
            
            # è·å–é¡¹ç›®ç›¸å…³ä»»åŠ¡
            project_tasks = [task for task in db_data.get('tasks', []) 
                           if task.get('project_id') == project_id]
            
            # è·å–é¡¹ç›®æŒ‡æ ‡
            metrics = db_data.get('project_metrics', {}).get(project_id, {})
            progress = metrics.get('progress_percentage', 0)
            
            # åˆ†ç±»ä»»åŠ¡
            completed_tasks = [task for task in project_tasks if task.get('status') == 'å·²å®Œæˆ']
            in_progress_tasks = [task for task in project_tasks if task.get('status') == 'è¿›è¡Œä¸­']
            overdue_tasks = [task for task in project_tasks if task.get('status') == 'é€¾æœŸ']
            
            return {
                "code": 200,
                "message": "æ—¥æŠ¥ç”ŸæˆæˆåŠŸ",
                "data": {
                    "project_id": project_id,
                    "project_name": project.get('project_name', f'é¡¹ç›®{project_id}'),
                    "report_date": datetime.now().strftime("%Y-%m-%d"),
                    "current_progress": f"{progress}%",
                    "completed_tasks_today": [task.get('task_name') for task in completed_tasks],
                    "in_progress_tasks": [task.get('task_name') for task in in_progress_tasks],
                    "overdue_tasks": [task.get('task_name') for task in overdue_tasks],
                    "summary": f"é¡¹ç›®{project.get('project_name')}å½“å‰è¿›åº¦{progress}%ï¼Œå·²å®Œæˆ{len(completed_tasks)}ä¸ªä»»åŠ¡ï¼Œè¿›è¡Œä¸­{len(in_progress_tasks)}ä¸ªä»»åŠ¡"
                }
            }
        else:
            return {
                "code": 200,
                "message": "æ—¥æŠ¥ç”ŸæˆæˆåŠŸ",
                "data": {
                    "project_id": project_id,
                    "project_name": f"é¡¹ç›®{project_id}",
                    "report_date": datetime.now().strftime("%Y-%m-%d"),
                    "current_progress": "75.0%",
                    "completed_tasks_today": ["éœ€æ±‚åˆ†æ", "ç³»ç»Ÿè®¾è®¡"],
                    "in_progress_tasks": ["å¼€å‘å®ç°"],
                    "overdue_tasks": [],
                    "summary": f"é¡¹ç›®{project_id}ä»Šæ—¥è¿›å±•è‰¯å¥½ï¼Œå®Œæˆäº†2ä¸ªä»»åŠ¡"
                }
            }
    except Exception as e:
        return {
            "code": 500,
            "message": f"ç”Ÿæˆæ—¥æŠ¥å¤±è´¥: {str(e)}",
            "data": None
        }

@app.get("/api/v1/auto-reduce/risk-monitoring/scan/{project_id}")
async def scan_project_risks(project_id: str):
    """æ‰«æé¡¹ç›®é£é™©ï¼ˆçœŸå®æ•°æ®ï¼‰"""
    import json
    import os
    
    try:
        # è¯»å–çœŸå®æ•°æ®åº“æ–‡ä»¶
        db_path = "industry_standard_database_extended.json"
        if os.path.exists(db_path):
            with open(db_path, 'r', encoding='utf-8') as f:
                db_data = json.load(f)
            
            # æŸ¥æ‰¾é¡¹ç›®ç›¸å…³é£é™©
            project_risks = [risk for risk in db_data.get('risks', []) 
                           if risk.get('project_id') == project_id]
            
            # è½¬æ¢ä¸ºå‘Šè­¦æ ¼å¼
            alerts = []
            for risk in project_risks:
                alerts.append({
                    "risk_id": risk.get('risk_id'),
                    "risk_title": risk.get('risk_title'),
                    "risk_level": risk.get('risk_level'),
                    "alert_message": risk.get('description'),
                    "mitigation_suggestion": risk.get('mitigation_plan', 'æš‚æ— ç¼“è§£è®¡åˆ’')
                })
            
            return {
                "code": 200,
                "message": "é£é™©æ‰«æå®Œæˆ",
                "data": {
                    "project_id": project_id,
                    "total_alerts": len(alerts),
                    "alerts": alerts
                }
            }
        else:
            return {
                "code": 200,
                "message": "é£é™©æ‰«æå®Œæˆ",
                "data": {
                    "project_id": project_id,
                    "total_alerts": 1,
                    "alerts": [
                        {
                            "risk_id": "RISK-001",
                            "risk_title": "è¿›åº¦å»¶æœŸé£é™©",
                            "risk_level": "ä¸­",
                            "alert_message": "é¡¹ç›®è¿›åº¦å¯èƒ½å»¶æœŸ",
                            "mitigation_suggestion": "å¢åŠ èµ„æºæŠ•å…¥"
                        }
                    ]
                }
            }
    except Exception as e:
        return {
            "code": 500,
            "message": f"é£é™©æ‰«æå¤±è´¥: {str(e)}",
            "data": None
        }

@app.get("/api/v1/auto-reduce/reports/project-summary/{project_id}")
async def generate_project_summary_report(project_id: str):
    """ç”Ÿæˆé¡¹ç›®æ±‡æ€»æŠ¥è¡¨ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    return {
        "code": 200,
        "message": "æŠ¥è¡¨ç”ŸæˆæˆåŠŸ",
        "data": {
            "project_id": project_id,
            "report_type": "PROJECT_SUMMARY",
            "report_format": "JSON",
            "generated_at": "2024-06-15T10:00:00",
            "data": {
                "report_title": "é¡¹ç›®æ±‡æ€»æŠ¥è¡¨",
                "items": [
                    {
                        "project_id": project_id,
                        "project_name": f"é¡¹ç›®{project_id}",
                        "status": "è¿›è¡Œä¸­",
                        "progress": 75.0
                    }
                ]
            }
        }
    }

# å…¨å±€å¯¹è¯è®°å¿†å­˜å‚¨
conversation_memory = {}

@app.post("/api/v1/auto-reduce/intelligent-chat/chat")
async def chat_with_ai(request: dict):
    """AIæ™ºèƒ½å¯¹è¯ - é›†æˆQwen_Maxæ¨¡å‹"""
    import json
    import os
    import requests
    from datetime import datetime
    
    try:
        user_message = request.get("message", "")
        session_id = request.get("session_id", "default")
        
        if not user_message:
            return {
                "code": 400,
                "message": "ç”¨æˆ·æ¶ˆæ¯ä¸èƒ½ä¸ºç©º",
                "data": None
            }
        
        # è·å–æˆ–åˆ›å»ºå¯¹è¯å†å²
        if session_id not in conversation_memory:
            conversation_memory[session_id] = []
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        conversation_memory[session_id].append({
            "role": "user",
            "content": user_message,
            "timestamp": datetime.now().isoformat()
        })
        
        # ä¿æŒæœ€è¿‘5è½®å¯¹è¯
        if len(conversation_memory[session_id]) > 10:  # 5è½®å¯¹è¯ = 10æ¡æ¶ˆæ¯
            conversation_memory[session_id] = conversation_memory[session_id][-10:]
        
        # è¯»å–é¡¹ç›®æ•°æ®ä½œä¸ºä¸Šä¸‹æ–‡
        db_path = "industry_standard_database_extended.json"
        project_context = ""
        if os.path.exists(db_path):
            with open(db_path, 'r', encoding='utf-8') as f:
                db_data = json.load(f)
            project_context = json.dumps(db_data, ensure_ascii=False, indent=2)
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯AIç®¡ç†è¾…åŠ©ç³»ç»Ÿï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·ç®¡ç†é¡¹ç›®ã€‚ä½ æœ‰ä»¥ä¸‹èƒ½åŠ›ï¼š

1. æ„å›¾åˆ†æï¼šç†è§£ç”¨æˆ·æƒ³è¦äº†è§£ä»€ä¹ˆ
2. æ•°æ®Agentè°ƒç”¨ï¼šé€šè¿‡ä¸“é—¨çš„æ•°æ®Agentè·å–å‡†ç¡®çš„æ•°æ®
3. ç»“æœè¾“å‡ºï¼šå°†æ•°æ®è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„å›ç­”ï¼Œå¹¶æä¾›æ•°æ®æ¥æºå’Œè®¡ç®—è¿‡ç¨‹
4. ä¸Šä¸‹æ–‡è®°å¿†ï¼šè®°ä½å¯¹è¯å†å²ï¼Œæä¾›è¿è´¯çš„å›ç­”

## æ•°æ®Agentä½¿ç”¨æŒ‡å—

å½“ç”¨æˆ·è¯¢é—®æ¶‰åŠæ•°æ®çš„é—®é¢˜æ—¶ï¼Œä½ éœ€è¦ï¼š
1. åˆ†æç”¨æˆ·æ„å›¾ï¼Œç¡®å®šéœ€è¦è°ƒç”¨å“ªä¸ªæ•°æ®Agent
2. è°ƒç”¨ç›¸åº”çš„æ•°æ®Agentè·å–æ•°æ®
3. åŸºäºæ•°æ®Agentè¿”å›çš„ç»“æœï¼Œæä¾›åŒ…å«ä»¥ä¸‹å†…å®¹çš„å›ç­”ï¼š
   - æ•°æ®æ¥æºè¯´æ˜
   - è®¡ç®—è¿‡ç¨‹è¯¦ç»†æ­¥éª¤
   - å…·ä½“çš„æ•°æ®æ”¯æ’‘
   - æ¸…æ™°çš„ç»“è®º

## å¯ç”¨çš„æ•°æ®Functionsï¼ˆçº¯æ•°æ®å¤„ç†ï¼‰ï¼š
- project_progressï¼šé¡¹ç›®è¿›åº¦æ•°æ®
- task_analysisï¼šä»»åŠ¡åˆ†ææ•°æ®
- risk_analysisï¼šé£é™©åˆ†ææ•°æ®ï¼ˆæ”¯æŒRAGæŒ‡å¯¼é›†æˆï¼‰
- budget_analysisï¼šé¢„ç®—åˆ†ææ•°æ®
- team_analysisï¼šå›¢é˜Ÿåˆ†ææ•°æ®
- progress_calculationï¼šè¿›åº¦è®¡ç®—è¯¦ç»†è¿‡ç¨‹
- gantt_analysisï¼šç”˜ç‰¹å›¾åˆ†ææ•°æ®
- chart_generationï¼šå›¾è¡¨ç”Ÿæˆæ•°æ®
- report_analysisï¼šå‘¨æŠ¥æœˆæŠ¥åˆ†ææ•°æ®

## å¯ç”¨çš„Agentï¼ˆä½¿ç”¨LLMï¼‰ï¼š
- knowledge_managementï¼šçŸ¥è¯†ç®¡ç†Agentï¼ˆä½¿ç”¨Qwen-Maxæ¨¡å‹è¿›è¡Œæ™ºèƒ½çŸ¥è¯†æå–å’Œåˆ†ç±»ï¼‰

## ä¸“å®¶å»ºè®®åŠŸèƒ½è¯´æ˜ï¼š
å½“ç”¨æˆ·è¯·æ±‚"ä¸“å®¶å»ºè®®"ã€"ä¸“ä¸šæŒ‡å¯¼"ã€"PMBOKæŒ‡å¯¼"ç­‰æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è°ƒç”¨risk_analysisæ•°æ®Functionå¹¶å¯ç”¨RAGæŒ‡å¯¼é›†æˆï¼Œä¸ºæ¯ä¸ªé£é™©é¡¹æä¾›åŸºäºPMBOKç¬¬ä¸ƒç‰ˆçš„ä¸“ä¸šæŒ‡å¯¼å»ºè®®ï¼ŒåŒ…æ‹¬ï¼š
- é£é™©ç±»å‹è¯†åˆ«
- PMBOKä¸“ä¸šæŒ‡å¯¼
- å¯æ‰§è¡Œçš„åº”å¯¹å»ºè®®
- é¡µç å¼•ç”¨éªŒè¯
- ä¼˜å…ˆè¡ŒåŠ¨é¡¹

## çŸ¥è¯†ç®¡ç†Agentè¯´æ˜ï¼š
å½“è°ƒç”¨knowledge_management Agentæ—¶ï¼Œç³»ç»Ÿä¼šä½¿ç”¨Qwen-Maxæ¨¡å‹è¿›è¡Œæ™ºèƒ½çŸ¥è¯†æå–å’Œåˆ†ç±»ï¼ŒæŒ‰ç…§5å¤§ç±»çŸ¥è¯†åˆ†ç±»è¿›è¡Œç»“æ„åŒ–æ±‡æ€»ã€‚

**é‡è¦ï¼šåœ¨å±•ç¤ºçŸ¥è¯†ç®¡ç†ç»“æœæ—¶ï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼Œç›´æ¥è¾“å‡º5å¤§ç±»çŸ¥è¯†åˆ†ç±»å†…å®¹ï¼š**

### äº”å¤§ç±»çŸ¥è¯†ç»†åˆ†
1. ğŸ“‹ é¡¹ç›®è¿‡ç¨‹ä¸æˆæœç±»çŸ¥è¯†
   - ç«‹é¡¹ä¿¡æ¯ï¼šæ™ºèƒ½ç®¡ç†ç³»ç»Ÿå¼€å‘é¡¹ç›®åŸºäºæ•°å­—åŒ–è½¬å‹éœ€æ±‚å¯åŠ¨ï¼Œç›®æ ‡æ˜¯æå‡ç®¡ç†æ•ˆç‡
   - è®¡åˆ’ä¸åŸºçº¿ï¼šé¢„è®¡å¼€å‘å‘¨æœŸ6ä¸ªæœˆï¼Œé¢„ç®—50ä¸‡å…ƒï¼Œéµå¾ªISO9001è´¨é‡æ ‡å‡†
   - æ‰§è¡Œè¿‡ç¨‹è®°å½•ï¼šå½“å‰è¿›åº¦65%ï¼Œå·²å®Œæˆéœ€æ±‚åˆ†æé˜¶æ®µï¼Œæ— é‡å¤§å˜æ›´
   - æˆæœæ–‡æ¡£ï¼šåŒ…æ‹¬ç³»ç»Ÿæ–‡æ¡£ã€æµ‹è¯•æŠ¥å‘Šï¼ˆå·²é€šè¿‡ï¼‰åŠç”¨æˆ·æ‰‹å†Œç­‰äº¤ä»˜ç‰©

2. ğŸ’¡ ç»éªŒä¸æ•™è®­ç±»çŸ¥è¯†
   - æˆåŠŸå®è·µï¼šé‡‡ç”¨æ•æ·å¼€å‘æ¨¡å¼ï¼Œåˆ©ç”¨Jiraè¿›è¡Œé¡¹ç›®ç®¡ç†ï¼Œé‡‡å–è¿­ä»£æ–¹å¼äº¤ä»˜äº§å“
   - å¤±è´¥/é—®é¢˜æ¡ˆä¾‹ï¼šé‡åˆ°æŠ€æœ¯éš¾é¢˜å¯¼è‡´è¿›åº¦å»¶è¿Ÿï¼Œä¸»è¦åŸå› æ˜¯å›¢é˜Ÿåœ¨æŸäº›æŠ€æœ¯é¢†åŸŸç¼ºä¹è¶³å¤Ÿç»éªŒ
   - æ”¹è¿›å»ºè®®ï¼šå»ºè®®åŠ å¼ºå‰æœŸæŠ€æœ¯è°ƒç ”å’ŒæŠ€æœ¯åŸ¹è®­ï¼ŒåŒæ—¶ä¼˜åŒ–èµ„æºåˆ†é…ä»¥æé«˜æ•ˆç‡

3. ğŸ¤ ç®¡ç†ä¸ååŒç±»çŸ¥è¯†
   - è´£ä»»çŸ©é˜µï¼šå®šä¹‰äº†é¡¹ç›®ç»ç†çš„è§’è‰²åŠå…¶èŒè´£ï¼Œå¦‚æ•´ä½“åè°ƒåŠå®¢æˆ·æ²Ÿé€šç­‰
   - å†³ç­–è®°å½•ï¼šå°±æŠ€æœ¯é€‰å‹è¿›è¡Œäº†è®¨è®ºï¼Œåœ¨æ€§èƒ½ä¸æˆæœ¬ä¹‹é—´å¯»æ‰¾å¹³è¡¡ç‚¹
   - æ²Ÿé€šè®°å½•ï¼šå®šæœŸä¸¾è¡Œå‘¨ä¾‹ä¼šï¼Œç¡®è®¤éœ€æ±‚å¹¶è°ƒæ•´é¡¹ç›®èŒƒå›´

4. ğŸ› ï¸ çŸ¥è¯†èµ„äº§ä¸æ–¹æ³•è®ºç±»çŸ¥è¯†
   - æ¨¡æ¿ä¸æ ‡å‡†ï¼šåˆ¶å®šäº†éœ€æ±‚åˆ†æã€æµ‹è¯•ç”¨ä¾‹ç¼–å†™çš„æ ‡å‡†æ ¼å¼åŠè¿›åº¦æŠ¥å‘Šæ¨¡æ¿
   - æµç¨‹ä¸å·¥å…·ï¼šä½¿ç”¨Gitè¿›è¡Œç‰ˆæœ¬æ§åˆ¶ï¼ŒJenkinsæ”¯æŒè‡ªåŠ¨åŒ–æµ‹è¯•ï¼ŒScrumæ¡†æ¶æŒ‡å¯¼æ•æ·å®è·µ
   - æŒ‡æ ‡ä¸åº¦é‡ï¼šç›‘æ§è¿›åº¦åå·®(5%)ã€æˆæœ¬åå·®(10%)åŠäº§å“è´¨é‡(95%)

5. ğŸ¢ ç»„ç»‡å±‚é¢ä»·å€¼ä¿¡æ¯
   - å¯å¤ç”¨çŸ¥è¯†ï¼šåˆ†äº«äº†ç®¡ç†ç³»ç»Ÿæ¶æ„è®¾è®¡ã€å¾®æœåŠ¡æŠ€æœ¯æ¶æ„åŠREST APIæ¥å£è§„èŒƒç­‰æ–¹é¢çš„çŸ¥è¯†
   - èƒ½åŠ›æˆç†Ÿåº¦ï¼šæ€»ç»“äº†æ•æ·ç®¡ç†çš„æœ€ä½³å®è·µã€é£é™©æ§åˆ¶çš„ç»éªŒæ•™è®­åŠæŠ€æœ¯é€‰å‹æ–¹é¢çš„ä¸“å®¶æ„è§
   - çŸ¥è¯†å…±äº«ï¼šæä¾›äº†é¡¹ç›®ç®¡ç†åŸ¹è®­ææ–™ã€å¸¸è§é—®é¢˜è§£ç­”æŒ‡å—åŠé¡¹ç›®æ€»ç»“äº¤æµä¼šç­‰å†…å®¹

**æ³¨æ„ï¼šä¸¥æ ¼ç¦æ­¢è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ï¼ŒåŒ…æ‹¬æ¦‚è§ˆä¿¡æ¯ã€è®¡ç®—è¿‡ç¨‹è¯´æ˜ã€æ•°æ®å¤„ç†æµç¨‹ç­‰ã€‚åªè¾“å‡ºä¸Šè¿°5å¤§ç±»çŸ¥è¯†åˆ†ç±»å†…å®¹ã€‚**

## æ•°æ®Functionså’ŒAgentè¿”å›æ ¼å¼è¯´æ˜ï¼š
æ¯ä¸ªæ•°æ®Functionå’ŒAgentéƒ½ä¼šè¿”å›åŒ…å«ä»¥ä¸‹å­—æ®µçš„ç»“æ„åŒ–æ•°æ®ï¼š
- successï¼šæ˜¯å¦æˆåŠŸ
- data_typeï¼šæ•°æ®ç±»å‹
- data_sourceï¼šæ•°æ®æ¥æº
- query_timeï¼šæŸ¥è¯¢æ—¶é—´
- dataï¼šå…·ä½“æ•°æ®
- calculation_methodï¼šè®¡ç®—æ–¹æ³•
- calculation_stepsï¼šè®¡ç®—æ­¥éª¤ï¼ˆå¦‚æœæœ‰ï¼‰
- data_fieldsï¼šæ•°æ®å­—æ®µè¯´æ˜

## å›ç­”è¦æ±‚ï¼š
1. å¿…é¡»æ˜ç¡®è¯´æ˜æ•°æ®æ¥æº
2. å¿…é¡»æä¾›è¯¦ç»†çš„è®¡ç®—è¿‡ç¨‹
3. å¿…é¡»ç”¨å…·ä½“æ•°æ®æ”¯æ’‘ç»“è®º
4. å¿…é¡»ä¿æŒå¯¹è¯çš„è¿è´¯æ€§
5. å¦‚æœæ•°æ®Agentè¿”å›å¤±è´¥ï¼Œè¦è¯´æ˜åŸå› 

å½“å‰é¡¹ç›®æ•°æ®ä¸Šä¸‹æ–‡ï¼š
{project_context}

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œåˆ†ææ„å›¾ï¼Œè°ƒç”¨ç›¸åº”çš„æ•°æ®Agentï¼Œå¹¶åŸºäºè¿”å›çš„æ•°æ®æä¾›è¯¦ç»†çš„å›ç­”ã€‚"""

        # è°ƒç”¨Qwen_Max APIï¼Œä¼ å…¥å¯¹è¯å†å²
        qwen_response = await call_qwen_api_with_history(system_prompt, conversation_memory[session_id])
        
        # å¦‚æœQwenè¿”å›éœ€è¦è°ƒç”¨å·¥å…·ï¼Œåˆ™æ‰§è¡Œå·¥å…·è°ƒç”¨
        if "éœ€è¦è°ƒç”¨" in qwen_response or "å·¥å…·" in qwen_response:
            # åˆ†æç”¨æˆ·æ„å›¾å¹¶è°ƒç”¨ç›¸åº”API
            api_result = await analyze_intent_and_call_api(user_message)
            if api_result:
                # å¦‚æœæ˜¯è¿›åº¦è®¡ç®—è¯·æ±‚ï¼Œè°ƒç”¨ä¸“é—¨çš„è¿›åº¦è®¡ç®—API
                if api_result.get("type") == "progress_calculation":
                    # ä»å¯¹è¯å†å²ä¸­æå–é¡¹ç›®ID
                    project_id = "PRJ-2024-001"  # é»˜è®¤é¡¹ç›®
                    for msg in conversation_memory[session_id]:
                        if "æ™ºèƒ½ç®¡ç†ç³»ç»Ÿ" in msg.get("content", ""):
                            project_id = "PRJ-2024-001"
                            break
                        elif "å®¢æˆ·å…³ç³»ç®¡ç†" in msg.get("content", ""):
                            project_id = "PRJ-2024-002"
                            break
                    
                    # è°ƒç”¨è¿›åº¦è®¡ç®—API
                    progress_calc_response = await get_project_progress_calculation(project_id)
                    if progress_calc_response["code"] == 200:
                        api_result = progress_calc_response["data"]
                
                # å°†APIç»“æœå‘é€ç»™Qwenè¿›è¡Œæœ€ç»ˆå¤„ç†
                final_prompt = f"ç”¨æˆ·é—®é¢˜ï¼š{user_message}\n\nAPIè°ƒç”¨ç»“æœï¼š{json.dumps(api_result, ensure_ascii=False)}\n\nè¯·åŸºäºè¿™äº›æ•°æ®ç»™å‡ºç”¨æˆ·å‹å¥½çš„å›ç­”ï¼Œç‰¹åˆ«æ˜¯è¦è¯¦ç»†è§£é‡Šè®¡ç®—è¿‡ç¨‹ã€‚"
                final_response = await call_qwen_api("", final_prompt)
                qwen_response = final_response
        
        # æ·»åŠ AIå›å¤åˆ°å¯¹è¯å†å²
        conversation_memory[session_id].append({
            "role": "assistant",
            "content": qwen_response,
            "timestamp": datetime.now().isoformat()
        })
        
        return {
            "code": 200,
            "message": "AIå¯¹è¯æˆåŠŸ",
            "data": {
                "session_id": session_id,
                "response": qwen_response,
                "timestamp": datetime.now().isoformat(),
                "model": "Qwen_Max"
            }
        }
        
    except Exception as e:
        return {
            "code": 500,
            "message": f"AIå¯¹è¯å¤±è´¥: {str(e)}",
            "data": None
        }

async def call_qwen_api(system_prompt: str, user_message: str) -> str:
    """è°ƒç”¨Qwen_Max API"""
    import requests
    
    api_key = "sk-369a880b04ca4e5cbfd139fe858e7d80"
    api_url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": user_message})
    
    data = {
        "model": "qwen-max",  # ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
        "input": {
            "messages": messages
        },
        "parameters": {
            "temperature": 0.7,
            "max_tokens": 2000  # å¢åŠ tokenæ•°é‡ä»¥æ”¯æŒå®Œæ•´å›ç­”
        }
    }
    
    try:
        response = requests.post(api_url, headers=headers, json=data, timeout=120)
        response.raise_for_status()
        
        result = response.json()
        if "output" in result and "text" in result["output"]:
            return result["output"]["text"]
        else:
            print(f"Qwen APIå“åº”æ ¼å¼å¼‚å¸¸: {result}")
            return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚"
            
    except requests.exceptions.Timeout:
        print("Qwen APIè°ƒç”¨è¶…æ—¶ (60ç§’)")
        return "æŠ±æ­‰ï¼ŒAIæœåŠ¡å“åº”è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•ã€‚å»ºè®®æ‚¨ï¼š\n1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n2. ç¨åé‡è¯•\n3. æˆ–ä½¿ç”¨æ•°æ®æŸ¥è¯¢åŠŸèƒ½è·å–é¡¹ç›®ä¿¡æ¯"
    except requests.exceptions.ConnectionError:
        print("Qwen APIè¿æ¥å¤±è´¥")
        return "æŠ±æ­‰ï¼ŒAIæœåŠ¡è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚"
    except Exception as e:
        print(f"Qwen APIè°ƒç”¨å¤±è´¥: {e}")
        return "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"

async def call_qwen_api_with_history(system_prompt: str, conversation_history: list) -> str:
    """è°ƒç”¨Qwen_Max APIï¼Œæ”¯æŒå¯¹è¯å†å²"""
    import requests
    
    api_key = "sk-369a880b04ca4e5cbfd139fe858e7d80"
    api_url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    
    # æ·»åŠ å¯¹è¯å†å²ï¼ˆæ’é™¤å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼Œå› ä¸ºå·²ç»åœ¨historyä¸­ï¼‰
    for msg in conversation_history[:-1]:  # æ’é™¤æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        messages.append({
            "role": msg["role"],
            "content": msg["content"]
        })
    
    # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    if conversation_history:
        current_user_msg = conversation_history[-1]
        if current_user_msg["role"] == "user":
            messages.append({
                "role": "user",
                "content": current_user_msg["content"]
            })
    
    data = {
        "model": "qwen-turbo",  # ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
        "input": {
            "messages": messages
        },
        "parameters": {
            "temperature": 0.7,
            "max_tokens": 12000  # å¢åŠ tokenæ•°é‡ä»¥æ”¯æŒå®Œæ•´å›ç­”
        }
    }
    
    try:
        response = requests.post(api_url, headers=headers, json=data, timeout=120)
        response.raise_for_status()
        
        result = response.json()
        if "output" in result and "text" in result["output"]:
            return result["output"]["text"]
        else:
            print(f"Qwen APIå“åº”æ ¼å¼å¼‚å¸¸: {result}")
            return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚"
            
    except requests.exceptions.Timeout:
        print("Qwen APIè°ƒç”¨è¶…æ—¶ (60ç§’)")
        return "æŠ±æ­‰ï¼ŒAIæœåŠ¡å“åº”è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•ã€‚å»ºè®®æ‚¨ï¼š\n1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n2. ç¨åé‡è¯•\n3. æˆ–ä½¿ç”¨æ•°æ®æŸ¥è¯¢åŠŸèƒ½è·å–é¡¹ç›®ä¿¡æ¯"
    except requests.exceptions.ConnectionError:
        print("Qwen APIè¿æ¥å¤±è´¥")
        return "æŠ±æ­‰ï¼ŒAIæœåŠ¡è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚"
    except Exception as e:
        print(f"Qwen APIè°ƒç”¨å¤±è´¥: {e}")
        return "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"

async def data_agent(query_type: str, query_params: dict = None) -> dict:
    """æ•°æ®è·å–Agent - ä¸“é—¨è´Ÿè´£è·å–å’Œè®¡ç®—æ•°æ®"""
    import json
    import os
    from datetime import datetime
    
    try:
        # è¯»å–é¡¹ç›®æ•°æ®
        db_path = "industry_standard_database_extended.json"
        if not os.path.exists(db_path):
            return {
                "success": False,
                "error": "æ•°æ®æºæ–‡ä»¶ä¸å­˜åœ¨",
                "data_source": db_path
            }
            
        with open(db_path, 'r', encoding='utf-8') as f:
            db_data = json.load(f)
        
        # æ ¹æ®æŸ¥è¯¢ç±»å‹è·å–æ•°æ®
        if query_type == "project_progress":
            return await get_project_progress_data(db_data, query_params)
        elif query_type == "task_analysis":
            return await get_task_analysis_data(db_data, query_params)
        elif query_type == "risk_analysis":
            return await get_risk_analysis_data(db_data, query_params)
        elif query_type == "budget_analysis":
            return await get_budget_analysis_data(db_data, query_params)
        elif query_type == "team_analysis":
            return await get_team_analysis_data(db_data, query_params)
        elif query_type == "progress_calculation":
            return await get_progress_calculation_data(db_data, query_params)
        elif query_type == "gantt_analysis":
            return await get_gantt_analysis_data(db_data, query_params)
        elif query_type == "chart_generation":
            return await get_chart_generation_data(db_data, query_params)
        elif query_type == "report_analysis":
            return await get_report_analysis_data(db_data, query_params)
        elif query_type == "knowledge_management":
            return await get_knowledge_management_data(db_data, query_params)
        else:
            return {
                "success": False,
                "error": f"æœªçŸ¥çš„æŸ¥è¯¢ç±»å‹: {query_type}",
                "available_types": ["project_progress", "task_analysis", "risk_analysis", "budget_analysis", "team_analysis", "progress_calculation", "gantt_analysis", "chart_generation", "report_analysis", "knowledge_management"]
            }
            
    except Exception as e:
        return {
            "success": False,
            "error": f"æ•°æ®è·å–å¤±è´¥: {str(e)}",
            "data_source": db_path
        }

async def get_project_progress_data(db_data: dict, query_params: dict = None) -> dict:
    """è·å–é¡¹ç›®è¿›åº¦æ•°æ®"""
    try:
        projects = db_data.get('projects', [])
        project_metrics = db_data.get('project_metrics', {})
        
        # å¦‚æœæŒ‡å®šäº†é¡¹ç›®IDï¼Œåªè¿”å›è¯¥é¡¹ç›®çš„è¿›åº¦
        if query_params and query_params.get('project_id'):
            project_id = query_params['project_id']
            project = next((p for p in projects if p.get('project_id') == project_id), None)
            if not project:
                return {
                    "success": False,
                    "error": f"é¡¹ç›® {project_id} ä¸å­˜åœ¨",
                    "data_source": "industry_standard_database.json"
                }
            
            metrics = project_metrics.get(project_id, {})
            return {
                "success": True,
                "data_type": "project_progress",
                "data_source": "industry_standard_database.json",
                "query_time": datetime.now().isoformat(),
                "project_id": project_id,
                "data": {
                    "project": project,
                    "metrics": metrics
                },
                "calculation_method": "ç›´æ¥ä»æ•°æ®åº“è¯»å–é¡¹ç›®æŒ‡æ ‡",
                "data_fields": {
                    "project": ["project_id", "project_name", "status", "start_date", "end_date", "budget", "actual_cost"],
                    "metrics": ["progress_percentage", "budget_utilization", "schedule_variance", "cost_variance", "quality_score", "risk_score"]
                }
            }
        
        # è¿”å›æ‰€æœ‰é¡¹ç›®è¿›åº¦
        return {
            "success": True,
            "data_type": "project_progress",
            "data_source": "industry_standard_database.json",
            "query_time": datetime.now().isoformat(),
            "data": {
                "projects": projects,
                "project_metrics": project_metrics
            },
            "calculation_method": "ç›´æ¥ä»æ•°æ®åº“è¯»å–æ‰€æœ‰é¡¹ç›®æ•°æ®",
            "data_fields": {
                "projects": ["project_id", "project_name", "status", "start_date", "end_date", "budget", "actual_cost"],
                "project_metrics": ["progress_percentage", "budget_utilization", "schedule_variance", "cost_variance", "quality_score", "risk_score"]
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"è·å–é¡¹ç›®è¿›åº¦æ•°æ®å¤±è´¥: {str(e)}",
            "data_source": "industry_standard_database.json"
        }

async def get_progress_calculation_data(db_data: dict, query_params: dict = None) -> dict:
    """è·å–è¿›åº¦è®¡ç®—è¯¦ç»†æ•°æ®"""
    try:
        project_id = query_params.get('project_id', 'PRJ-2024-001') if query_params else 'PRJ-2024-001'
        
        # è·å–é¡¹ç›®ä¿¡æ¯
        projects = db_data.get('projects', [])
        project = next((p for p in projects if p.get('project_id') == project_id), None)
        if not project:
            return {
                "success": False,
                "error": f"é¡¹ç›® {project_id} ä¸å­˜åœ¨",
                "data_source": "industry_standard_database.json"
            }
        
        # è·å–é¡¹ç›®ç›¸å…³ä»»åŠ¡
        tasks = db_data.get('tasks', [])
        project_tasks = [task for task in tasks if task.get('project_id') == project_id]
        
        # è·å–é¡¹ç›®æŒ‡æ ‡
        project_metrics = db_data.get('project_metrics', {})
        metrics = project_metrics.get(project_id, {})
        
        # è®¡ç®—è¯¦ç»†è¿›åº¦
        total_tasks = len(project_tasks)
        if total_tasks == 0:
            return {
                "success": True,
                "data_type": "progress_calculation",
                "data_source": "industry_standard_database.json",
                "query_time": datetime.now().isoformat(),
                "project_id": project_id,
                "data": {
                    "overall_progress": 0,
                    "calculation_method": "æ— ä»»åŠ¡æ•°æ®",
                    "detailed_breakdown": []
                },
                "calculation_method": "æ— ä»»åŠ¡æ•°æ®ï¼Œè¿›åº¦ä¸º0%",
                "data_fields": {
                    "tasks": [],
                    "metrics": list(metrics.keys())
                }
            }
        
        # æŒ‰çŠ¶æ€åˆ†ç»„ä»»åŠ¡
        status_groups = {}
        for task in project_tasks:
            status = task.get('status', 'æœªçŸ¥')
            if status not in status_groups:
                status_groups[status] = []
            status_groups[status].append(task)
        
        # è®¡ç®—å„çŠ¶æ€ä»»åŠ¡è¿›åº¦
        detailed_breakdown = []
        total_weighted_progress = 0
        total_weight = 0
        
        for status, tasks_in_status in status_groups.items():
            status_progress = 0
            status_weight = len(tasks_in_status)
            
            for task in tasks_in_status:
                task_progress = task.get('progress_percentage', 0)
                status_progress += task_progress
            
            avg_status_progress = status_progress / len(tasks_in_status) if tasks_in_status else 0
            weighted_progress = avg_status_progress * status_weight
            
            total_weighted_progress += weighted_progress
            total_weight += status_weight
            
            detailed_breakdown.append({
                "status": status,
                "task_count": len(tasks_in_status),
                "average_progress": round(avg_status_progress, 2),
                "weighted_progress": round(weighted_progress, 2),
                "tasks": [
                    {
                        "task_id": task.get('task_id'),
                        "task_name": task.get('task_name'),
                        "progress": task.get('progress_percentage', 0)
                    } for task in tasks_in_status
                ]
            })
        
        # è®¡ç®—æ•´ä½“è¿›åº¦
        calculated_progress = total_weighted_progress / total_weight if total_weight > 0 else 0
        db_progress = metrics.get('progress_percentage', 0)
        
        return {
            "success": True,
            "data_type": "progress_calculation",
            "data_source": "industry_standard_database.json",
            "query_time": datetime.now().isoformat(),
            "project_id": project_id,
            "data": {
                "project_name": project.get('project_name'),
                "calculated_progress": round(calculated_progress, 2),
                "database_progress": db_progress,
                "calculation_method": "åŠ æƒå¹³å‡æ³•",
                "formula": "æ•´ä½“è¿›åº¦ = Î£(çŠ¶æ€å¹³å‡è¿›åº¦ Ã— çŠ¶æ€ä»»åŠ¡æ•°) / æ€»ä»»åŠ¡æ•°",
                "total_tasks": total_tasks,
                "total_weighted_progress": round(total_weighted_progress, 2),
                "total_weight": total_weight,
                "detailed_breakdown": detailed_breakdown,
                "metrics_from_db": metrics
            },
            "calculation_method": "åŸºäºä»»åŠ¡è¿›åº¦çš„åŠ æƒå¹³å‡è®¡ç®—",
            "calculation_steps": [
                f"1. è·å–é¡¹ç›® {project_id} çš„æ‰€æœ‰ä»»åŠ¡æ•°æ®",
                f"2. æŒ‰çŠ¶æ€åˆ†ç»„ä»»åŠ¡ï¼Œå…± {len(status_groups)} ä¸ªçŠ¶æ€ç»„",
                f"3. è®¡ç®—æ¯ä¸ªçŠ¶æ€ç»„çš„å¹³å‡è¿›åº¦",
                f"4. ä½¿ç”¨åŠ æƒå¹³å‡æ³•è®¡ç®—æ•´ä½“è¿›åº¦: {round(calculated_progress, 2)}%",
                f"5. å¯¹æ¯”æ•°æ®åº“ä¸­çš„è¿›åº¦æŒ‡æ ‡: {db_progress}%"
            ],
            "data_fields": {
                "tasks": ["task_id", "task_name", "status", "progress_percentage", "project_id"],
                "metrics": list(metrics.keys())
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"è·å–è¿›åº¦è®¡ç®—æ•°æ®å¤±è´¥: {str(e)}",
            "data_source": "industry_standard_database.json"
        }

async def get_task_analysis_data(db_data: dict, query_params: dict = None) -> dict:
    """è·å–ä»»åŠ¡åˆ†ææ•°æ®"""
    try:
        tasks = db_data.get('tasks', [])
        
        # å¦‚æœæŒ‡å®šäº†é¡¹ç›®IDï¼Œåªè¿”å›è¯¥é¡¹ç›®çš„ä»»åŠ¡
        if query_params and query_params.get('project_id'):
            project_id = query_params['project_id']
            project_tasks = [task for task in tasks if task.get('project_id') == project_id]
            
            # æŒ‰çŠ¶æ€ç»Ÿè®¡
            status_stats = {}
            for task in project_tasks:
                status = task.get('status', 'æœªçŸ¥')
                if status not in status_stats:
                    status_stats[status] = {'count': 0, 'total_progress': 0, 'tasks': []}
                status_stats[status]['count'] += 1
                status_stats[status]['total_progress'] += task.get('progress_percentage', 0)
                status_stats[status]['tasks'].append(task)
            
            # è®¡ç®—å¹³å‡è¿›åº¦
            for status, stats in status_stats.items():
                stats['average_progress'] = round(stats['total_progress'] / stats['count'], 2) if stats['count'] > 0 else 0
            
            return {
                "success": True,
                "data_type": "task_analysis",
                "data_source": "industry_standard_database.json",
                "query_time": datetime.now().isoformat(),
                "project_id": project_id,
                "data": {
                    "total_tasks": len(project_tasks),
                    "status_breakdown": status_stats,
                    "tasks": project_tasks
                },
                "calculation_method": "æŒ‰çŠ¶æ€åˆ†ç»„ç»Ÿè®¡ä»»åŠ¡æ•°é‡å’Œè¿›åº¦",
                "data_fields": {
                    "tasks": ["task_id", "task_name", "status", "progress_percentage", "priority", "assigned_to", "project_id"]
                }
            }
        
        # è¿”å›æ‰€æœ‰ä»»åŠ¡åˆ†æ
        all_status_stats = {}
        for task in tasks:
            status = task.get('status', 'æœªçŸ¥')
            if status not in all_status_stats:
                all_status_stats[status] = {'count': 0, 'total_progress': 0}
            all_status_stats[status]['count'] += 1
            all_status_stats[status]['total_progress'] += task.get('progress_percentage', 0)
        
        # è®¡ç®—å¹³å‡è¿›åº¦
        for status, stats in all_status_stats.items():
            stats['average_progress'] = round(stats['total_progress'] / stats['count'], 2) if stats['count'] > 0 else 0
        
        return {
            "success": True,
            "data_type": "task_analysis",
            "data_source": "industry_standard_database.json",
            "query_time": datetime.now().isoformat(),
            "data": {
                "total_tasks": len(tasks),
                "status_breakdown": all_status_stats,
                "tasks": tasks
            },
            "calculation_method": "æŒ‰çŠ¶æ€åˆ†ç»„ç»Ÿè®¡æ‰€æœ‰ä»»åŠ¡",
            "data_fields": {
                "tasks": ["task_id", "task_name", "status", "progress_percentage", "priority", "assigned_to", "project_id"]
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"è·å–ä»»åŠ¡åˆ†ææ•°æ®å¤±è´¥: {str(e)}",
            "data_source": "industry_standard_database.json"
        }

async def get_risk_analysis_data(db_data: dict, query_params: dict = None) -> dict:
    """è·å–é£é™©åˆ†ææ•°æ®ï¼ˆé›†æˆRAGæŒ‡å¯¼ï¼‰"""
    try:
        risks = db_data.get('risks', [])
        
        # å¦‚æœæŒ‡å®šäº†é¡¹ç›®IDï¼Œåªè¿”å›è¯¥é¡¹ç›®çš„é£é™©
        if query_params and query_params.get('project_id'):
            project_id = query_params['project_id']
            project_risks = [risk for risk in risks if risk.get('project_id') == project_id]
        else:
            project_risks = risks
        
        # æŒ‰é£é™©ç­‰çº§ç»Ÿè®¡
        level_stats = {}
        for risk in project_risks:
            level = risk.get('risk_level', 'æœªçŸ¥')
            if level not in level_stats:
                level_stats[level] = {'count': 0, 'risks': []}
            level_stats[level]['count'] += 1
            level_stats[level]['risks'].append(risk)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦RAGæŒ‡å¯¼
        include_rag_guidance = query_params and query_params.get('include_rag_guidance', False)
        rag_guidance = []
        
        if include_rag_guidance and project_risks:
            try:
                # å¯¼å…¥RAGæŒ‡å¯¼é›†æˆ
                from rag_guidance_integration import RAGGuidanceIntegration
                rag_integration = RAGGuidanceIntegration()
                
                # ä¸ºæ¯ä¸ªé£é™©ç”ŸæˆRAGæŒ‡å¯¼ï¼ˆæ·»åŠ è¶…æ—¶å¤„ç†ï¼‰
                import asyncio
                for i, risk in enumerate(project_risks, 1):
                    try:
                        print(f"   å¤„ç†é£é™© {i}/{len(project_risks)}: {risk.get('risk_title', 'æœªçŸ¥é£é™©')}")
                        # è®¾ç½®15ç§’è¶…æ—¶ï¼ˆå‡å°‘è¶…æ—¶æ—¶é—´ï¼‰
                        guidance = await asyncio.wait_for(
                            rag_integration.generate_risk_guidance(risk),
                            timeout=15.0
                        )
                        rag_guidance.append(guidance)
                        print(f"   âœ… é£é™© {i} æŒ‡å¯¼ç”ŸæˆæˆåŠŸ")
                    except asyncio.TimeoutError:
                        print(f"   âš ï¸ é£é™© {i} æŒ‡å¯¼ç”Ÿæˆè¶…æ—¶ï¼Œä½¿ç”¨å¿«é€Ÿå¤‡é€‰æ–¹æ¡ˆ")
                        # æ·»åŠ ä¸€ä¸ªå¿«é€Ÿçš„å¤‡é€‰æŒ‡å¯¼
                        rag_guidance.append({
                            "risk_id": risk.get('risk_id'),
                            "risk_title": risk.get('risk_title', ''),
                            "risk_level": risk.get('risk_level', 'æœªçŸ¥'),
                            "risk_type": "å¿«é€Ÿåˆ†æ",
                            "pmbok_guidance": [{
                                "content": f"é’ˆå¯¹é£é™©'{risk.get('risk_title', '')}'ï¼Œå»ºè®®é‡‡ç”¨ä»¥ä¸‹PMBOKç¬¬ä¸ƒç‰ˆé£é™©ç®¡ç†ç­–ç•¥ï¼š1. é£é™©è¯†åˆ«ä¸è¯„ä¼° 2. åˆ¶å®šåº”å¯¹è®¡åˆ’ 3. ç›‘æ§ä¸æ§åˆ¶",
                                "page_number": "ç¬¬11ç« ",
                                "section": "é¡¹ç›®é£é™©ç®¡ç†"
                            }],
                            "guidance_summary": f"é£é™©'{risk.get('risk_title', '')}'éœ€è¦é‡ç‚¹å…³æ³¨ï¼Œå»ºè®®åˆ¶å®šè¯¦ç»†çš„åº”å¯¹è®¡åˆ’",
                            "actionable_advice": ["åˆ¶å®šé£é™©åº”å¯¹è®¡åˆ’", "å»ºç«‹ç›‘æ§æœºåˆ¶", "å‡†å¤‡åº”æ€¥é¢„æ¡ˆ"],
                            "priority_actions": ["ç«‹å³è¯„ä¼°å½±å“", "åˆ¶å®šåº”å¯¹ç­–ç•¥", "åˆ†é…è´£ä»»äºº"],
                            "fallback_mode": True
                        })
                    except Exception as e:
                        print(f"   âŒ é£é™© {i} æŒ‡å¯¼ç”Ÿæˆå¤±è´¥: {str(e)}")
                        # æ·»åŠ ä¸€ä¸ªå¿«é€Ÿçš„å¤‡é€‰æŒ‡å¯¼
                        rag_guidance.append({
                            "risk_id": risk.get('risk_id'),
                            "risk_title": risk.get('risk_title', ''),
                            "risk_level": risk.get('risk_level', 'æœªçŸ¥'),
                            "error": f"ç”Ÿæˆå¤±è´¥: {str(e)}",
                            "pmbok_guidance": [{
                                "content": f"é’ˆå¯¹é£é™©'{risk.get('risk_title', '')}'ï¼Œå»ºè®®å‚è€ƒPMBOKç¬¬ä¸ƒç‰ˆé£é™©ç®¡ç†ç« èŠ‚è¿›è¡Œé£é™©åº”å¯¹",
                                "page_number": "ç¬¬11ç« ",
                                "section": "é¡¹ç›®é£é™©ç®¡ç†"
                            }],
                            "guidance_summary": f"é£é™©'{risk.get('risk_title', '')}'éœ€è¦é‡ç‚¹å…³æ³¨",
                            "actionable_advice": ["åˆ¶å®šé£é™©åº”å¯¹è®¡åˆ’", "å»ºç«‹ç›‘æ§æœºåˆ¶"],
                            "priority_actions": ["è¯„ä¼°é£é™©å½±å“", "åˆ¶å®šåº”å¯¹ç­–ç•¥"],
                            "fallback_mode": True
                        })
                    
            except Exception as e:
                print(f"RAGæŒ‡å¯¼ç”Ÿæˆå¤±è´¥: {str(e)}")
                rag_guidance = []
        
        result = {
            "success": True,
            "data_type": "risk_analysis",
            "data_source": "industry_standard_database.json",
            "query_time": datetime.now().isoformat(),
            "project_id": query_params.get('project_id') if query_params else None,
            "data": {
                "total_risks": len(project_risks),
                "level_breakdown": level_stats,
                "risks": project_risks
            },
            "calculation_method": "æŒ‰é£é™©ç­‰çº§åˆ†ç»„ç»Ÿè®¡" + (" + PMBOKæŒ‡å¯¼é›†æˆ" if include_rag_guidance else ""),
            "data_fields": {
                "risks": ["risk_id", "risk_title", "risk_level", "probability", "impact", "description", "mitigation_plan", "project_id"]
            }
        }
        
        # å¦‚æœåŒ…å«RAGæŒ‡å¯¼ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
        if include_rag_guidance and rag_guidance:
            result["data"]["rag_guidance"] = rag_guidance
            result["rag_integration"] = {
                "enabled": True,
                "guidance_count": len(rag_guidance),
                "pmbok_source": "PMBOKç¬¬ä¸ƒç‰ˆä¸­æ–‡ç‰ˆ"
            }
        
        return result
        
    except Exception as e:
        return {
            "success": False,
            "error": f"è·å–é£é™©åˆ†ææ•°æ®å¤±è´¥: {str(e)}",
            "data_source": "industry_standard_database.json"
        }

async def get_budget_analysis_data(db_data: dict, query_params: dict = None) -> dict:
    """è·å–é¢„ç®—åˆ†ææ•°æ®"""
    try:
        projects = db_data.get('projects', [])
        
        # å¦‚æœæŒ‡å®šäº†é¡¹ç›®IDï¼Œåªè¿”å›è¯¥é¡¹ç›®çš„é¢„ç®—
        if query_params and query_params.get('project_id'):
            project_id = query_params['project_id']
            project = next((p for p in projects if p.get('project_id') == project_id), None)
            if not project:
                return {
                    "success": False,
                    "error": f"é¡¹ç›® {project_id} ä¸å­˜åœ¨",
                    "data_source": "industry_standard_database.json"
                }
            
            budget = project.get('budget', 0)
            actual_cost = project.get('actual_cost', 0)
            utilization_rate = (actual_cost / budget * 100) if budget > 0 else 0
            
            return {
                "success": True,
                "data_type": "budget_analysis",
                "data_source": "industry_standard_database.json",
                "query_time": datetime.now().isoformat(),
                "project_id": project_id,
                "data": {
                    "project": project,
                    "budget": budget,
                    "actual_cost": actual_cost,
                    "utilization_rate": round(utilization_rate, 2),
                    "remaining_budget": budget - actual_cost
                },
                "calculation_method": "é¢„ç®—ä½¿ç”¨ç‡ = (å®é™…æˆæœ¬ / é¢„ç®—) Ã— 100%",
                "calculation_steps": [
                    f"1. è·å–é¡¹ç›® {project_id} çš„é¢„ç®—æ•°æ®: Â¥{budget:,.2f}",
                    f"2. è·å–é¡¹ç›® {project_id} çš„å®é™…æˆæœ¬: Â¥{actual_cost:,.2f}",
                    f"3. è®¡ç®—ä½¿ç”¨ç‡: ({actual_cost:,.2f} / {budget:,.2f}) Ã— 100% = {utilization_rate:.2f}%",
                    f"4. è®¡ç®—å‰©ä½™é¢„ç®—: {budget:,.2f} - {actual_cost:,.2f} = Â¥{budget - actual_cost:,.2f}"
                ],
                "data_fields": {
                    "project": ["project_id", "project_name", "budget", "actual_cost", "start_date", "end_date"]
                }
            }
        
        # è¿”å›æ‰€æœ‰é¡¹ç›®çš„é¢„ç®—åˆ†æ
        total_budget = sum(p.get('budget', 0) for p in projects)
        total_cost = sum(p.get('actual_cost', 0) for p in projects)
        overall_utilization = (total_cost / total_budget * 100) if total_budget > 0 else 0
        
        project_budgets = []
        for project in projects:
            budget = project.get('budget', 0)
            actual_cost = project.get('actual_cost', 0)
            utilization_rate = (actual_cost / budget * 100) if budget > 0 else 0
            
            project_budgets.append({
                "project_id": project.get('project_id'),
                "project_name": project.get('project_name'),
                "budget": budget,
                "actual_cost": actual_cost,
                "utilization_rate": round(utilization_rate, 2),
                "remaining_budget": budget - actual_cost
            })
        
        return {
            "success": True,
            "data_type": "budget_analysis",
            "data_source": "industry_standard_database.json",
            "query_time": datetime.now().isoformat(),
            "data": {
                "total_budget": total_budget,
                "total_cost": total_cost,
                "overall_utilization": round(overall_utilization, 2),
                "remaining_budget": total_budget - total_cost,
                "project_budgets": project_budgets
            },
            "calculation_method": "æ±‡æ€»æ‰€æœ‰é¡¹ç›®çš„é¢„ç®—å’Œæˆæœ¬æ•°æ®",
            "calculation_steps": [
                f"1. æ±‡æ€»æ‰€æœ‰é¡¹ç›®é¢„ç®—: Â¥{total_budget:,.2f}",
                f"2. æ±‡æ€»æ‰€æœ‰é¡¹ç›®å®é™…æˆæœ¬: Â¥{total_cost:,.2f}",
                f"3. è®¡ç®—æ€»ä½“ä½¿ç”¨ç‡: ({total_cost:,.2f} / {total_budget:,.2f}) Ã— 100% = {overall_utilization:.2f}%",
                f"4. è®¡ç®—æ€»ä½“å‰©ä½™é¢„ç®—: Â¥{total_budget - total_cost:,.2f}"
            ],
            "data_fields": {
                "projects": ["project_id", "project_name", "budget", "actual_cost", "start_date", "end_date"]
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"è·å–é¢„ç®—åˆ†ææ•°æ®å¤±è´¥: {str(e)}",
            "data_source": "industry_standard_database.json"
        }

async def get_team_analysis_data(db_data: dict, query_params: dict = None) -> dict:
    """è·å–å›¢é˜Ÿåˆ†ææ•°æ®"""
    try:
        users = db_data.get('users', [])
        resources = db_data.get('resources', [])
        
        # æŒ‰è§’è‰²ç»Ÿè®¡ç”¨æˆ·
        role_stats = {}
        for user in users:
            role = user.get('role', 'æœªçŸ¥')
            if role not in role_stats:
                role_stats[role] = {'count': 0, 'users': []}
            role_stats[role]['count'] += 1
            role_stats[role]['users'].append(user)
        
        # æŒ‰èµ„æºç±»å‹ç»Ÿè®¡
        resource_stats = {}
        for resource in resources:
            resource_type = resource.get('resource_type', 'æœªçŸ¥')
            if resource_type not in resource_stats:
                resource_stats[resource_type] = {'count': 0, 'resources': []}
            resource_stats[resource_type]['count'] += 1
            resource_stats[resource_type]['resources'].append(resource)
        
        return {
            "success": True,
            "data_type": "team_analysis",
            "data_source": "industry_standard_database.json",
            "query_time": datetime.now().isoformat(),
            "data": {
                "total_users": len(users),
                "total_resources": len(resources),
                "role_breakdown": role_stats,
                "resource_breakdown": resource_stats,
                "users": users,
                "resources": resources
            },
            "calculation_method": "æŒ‰è§’è‰²å’Œèµ„æºç±»å‹åˆ†ç»„ç»Ÿè®¡",
            "data_fields": {
                "users": ["user_id", "username", "email", "role", "department", "skills"],
                "resources": ["resource_id", "resource_name", "resource_type", "availability", "cost_per_hour"]
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"è·å–å›¢é˜Ÿåˆ†ææ•°æ®å¤±è´¥: {str(e)}",
            "data_source": "industry_standard_database.json"
        }

async def get_gantt_analysis_data(db_data: dict, query_params: dict = None) -> dict:
    """è·å–ç”˜ç‰¹å›¾åˆ†ææ•°æ®"""
    try:
        gantt_charts = db_data.get("gantt_charts", [])
        
        if not gantt_charts:
            return {
                "success": False,
                "error": "æœªæ‰¾åˆ°ç”˜ç‰¹å›¾æ•°æ®",
                "data_source": "industry_standard_database_extended.json"
            }
        
        # åˆ†æç”˜ç‰¹å›¾æ•°æ®
        gantt_analysis = {
            "total_gantt_charts": len(gantt_charts),
            "methodology_breakdown": {},
            "project_progress": {},
            "sprint_velocity": {},
            "phase_completion": {}
        }
        
        for gantt in gantt_charts:
            methodology = gantt.get("methodology", "æœªçŸ¥")
            project_id = gantt.get("project_id")
            project_name = gantt.get("project_name")
            
            # ç»Ÿè®¡æ–¹æ³•è®ºåˆ†å¸ƒ
            if methodology not in gantt_analysis["methodology_breakdown"]:
                gantt_analysis["methodology_breakdown"][methodology] = 0
            gantt_analysis["methodology_breakdown"][methodology] += 1
            
            # åˆ†æç€‘å¸ƒæ¨¡å‹é¡¹ç›®
            if methodology == "ç€‘å¸ƒæ¨¡å‹" and "phases" in gantt:
                phases = gantt["phases"]
                completed_phases = sum(1 for phase in phases if phase.get("status") == "å·²å®Œæˆ")
                total_phases = len(phases)
                progress_percentage = (completed_phases / total_phases * 100) if total_phases > 0 else 0
                
                gantt_analysis["project_progress"][project_id] = {
                    "project_name": project_name,
                    "methodology": methodology,
                    "completed_phases": completed_phases,
                    "total_phases": total_phases,
                    "progress_percentage": round(progress_percentage, 1),
                    "phases": phases
                }
            
            # åˆ†ææ•æ·å¼€å‘é¡¹ç›®
            elif methodology == "æ•æ·å¼€å‘" and "sprints" in gantt:
                sprints = gantt["sprints"]
                completed_sprints = sum(1 for sprint in sprints if sprint.get("status") == "å·²å®Œæˆ")
                total_sprints = len(sprints)
                progress_percentage = (completed_sprints / total_sprints * 100) if total_sprints > 0 else 0
                
                # è®¡ç®—å¹³å‡é€Ÿåº¦
                velocities = [sprint.get("velocity", 0) for sprint in sprints if sprint.get("velocity")]
                avg_velocity = sum(velocities) / len(velocities) if velocities else 0
                
                gantt_analysis["project_progress"][project_id] = {
                    "project_name": project_name,
                    "methodology": methodology,
                    "completed_sprints": completed_sprints,
                    "total_sprints": total_sprints,
                    "progress_percentage": round(progress_percentage, 1),
                    "average_velocity": round(avg_velocity, 1),
                    "sprints": sprints
                }
                
                gantt_analysis["sprint_velocity"][project_id] = {
                    "project_name": project_name,
                    "velocities": velocities,
                    "average_velocity": round(avg_velocity, 1)
                }
        
        return {
            "success": True,
            "data_type": "gantt_analysis",
            "data_source": "industry_standard_database_extended.json",
            "query_time": datetime.now().isoformat(),
            "data": gantt_analysis,
            "calculation_method": "åŸºäºç”˜ç‰¹å›¾æ•°æ®ç»Ÿè®¡é¡¹ç›®è¿›åº¦ã€æ–¹æ³•è®ºåˆ†å¸ƒå’Œæ•æ·é€Ÿåº¦",
            "calculation_steps": [
                "1. ç»Ÿè®¡ç”˜ç‰¹å›¾æ€»æ•°å’Œæ–¹æ³•è®ºåˆ†å¸ƒ",
                "2. åˆ†æç€‘å¸ƒæ¨¡å‹é¡¹ç›®çš„é˜¶æ®µå®Œæˆæƒ…å†µ",
                "3. åˆ†ææ•æ·å¼€å‘é¡¹ç›®çš„Sprintå®Œæˆæƒ…å†µå’Œé€Ÿåº¦",
                "4. è®¡ç®—å„é¡¹ç›®çš„æ•´ä½“è¿›åº¦ç™¾åˆ†æ¯”"
            ],
            "data_fields": {
                "total_gantt_charts": "ç”˜ç‰¹å›¾æ€»æ•°",
                "methodology_breakdown": "æ–¹æ³•è®ºåˆ†å¸ƒç»Ÿè®¡",
                "project_progress": "å„é¡¹ç›®è¿›åº¦è¯¦æƒ…",
                "sprint_velocity": "æ•æ·é¡¹ç›®é€Ÿåº¦åˆ†æ"
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"ç”˜ç‰¹å›¾åˆ†æå¤±è´¥: {str(e)}",
            "data_source": "industry_standard_database_extended.json"
        }

async def get_chart_generation_data(db_data: dict, query_params: dict = None) -> dict:
    """ç”Ÿæˆå›¾è¡¨æ•°æ®"""
    try:
        # è·å–é¡¹ç›®æ•°æ®
        projects = db_data.get("projects", [])
        gantt_charts = db_data.get("gantt_charts", [])
        
        # ç”Ÿæˆç”˜ç‰¹å›¾æ•°æ®
        gantt_chart_data = []
        for gantt in gantt_charts:
            project_id = gantt.get("project_id")
            project_name = gantt.get("project_name")
            methodology = gantt.get("methodology")
            
            if methodology == "ç€‘å¸ƒæ¨¡å‹" and "phases" in gantt:
                for phase in gantt["phases"]:
                    phase_name = phase.get("phase_name")
                    start_date = phase.get("start_date", "").split("T")[0]
                    end_date = phase.get("end_date", "").split("T")[0]
                    progress = phase.get("progress_percentage", 0)
                    status = phase.get("status", "æœªå¼€å§‹")
                    
                    gantt_chart_data.append({
                        "project": project_name,
                        "phase": phase_name,
                        "start_date": start_date,
                        "end_date": end_date,
                        "progress": progress,
                        "status": status,
                        "methodology": methodology
                    })
            
            elif methodology == "æ•æ·å¼€å‘" and "sprints" in gantt:
                for sprint in gantt["sprints"]:
                    sprint_name = sprint.get("sprint_name")
                    start_date = sprint.get("start_date", "").split("T")[0]
                    end_date = sprint.get("end_date", "").split("T")[0]
                    progress = sprint.get("progress_percentage", 0)
                    status = sprint.get("status", "æœªå¼€å§‹")
                    velocity = sprint.get("velocity", 0)
                    
                    gantt_chart_data.append({
                        "project": project_name,
                        "phase": sprint_name,
                        "start_date": start_date,
                        "end_date": end_date,
                        "progress": progress,
                        "status": status,
                        "methodology": methodology,
                        "velocity": velocity
                    })
        
        # ç”Ÿæˆé¡¹ç›®è¿›åº¦å›¾è¡¨æ•°æ®
        progress_chart_data = []
        for project in projects:
            project_id = project.get("project_id")
            project_name = project.get("project_name")
            budget = project.get("budget", 0)
            actual_cost = project.get("actual_cost", 0)
            budget_utilization = (actual_cost / budget * 100) if budget > 0 else 0
            
            progress_chart_data.append({
                "project_id": project_id,
                "project_name": project_name,
                "budget": budget,
                "actual_cost": actual_cost,
                "budget_utilization": round(budget_utilization, 1)
            })
        
        # ç”Ÿæˆç”˜ç‰¹å›¾Mermaidä»£ç 
        mermaid_gantt = generate_mermaid_gantt(gantt_chart_data)
        
        return {
            "success": True,
            "data_type": "chart_generation",
            "data_source": "industry_standard_database_extended.json",
            "query_time": datetime.now().isoformat(),
            "data": {
                "gantt_chart_data": gantt_chart_data,
                "progress_chart_data": progress_chart_data,
                "mermaid_gantt": mermaid_gantt,
                "chart_types": ["ç”˜ç‰¹å›¾", "é¡¹ç›®è¿›åº¦å›¾", "é¢„ç®—ä½¿ç”¨å›¾", "æ–¹æ³•è®ºåˆ†å¸ƒå›¾"]
            },
            "calculation_method": "åŸºäºé¡¹ç›®æ•°æ®å’Œç”˜ç‰¹å›¾æ•°æ®ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨",
            "calculation_steps": [
                "1. æå–ç”˜ç‰¹å›¾æ•°æ®ï¼ŒåŒ…æ‹¬é˜¶æ®µ/Sprintä¿¡æ¯",
                "2. è®¡ç®—é¡¹ç›®é¢„ç®—ä½¿ç”¨ç‡",
                "3. ç”ŸæˆMermaidç”˜ç‰¹å›¾ä»£ç ",
                "4. å‡†å¤‡å›¾è¡¨æ•°æ®ç”¨äºå¯è§†åŒ–å±•ç¤º"
            ],
            "data_fields": {
                "gantt_chart_data": "ç”˜ç‰¹å›¾æ•°æ®",
                "progress_chart_data": "é¡¹ç›®è¿›åº¦æ•°æ®",
                "mermaid_gantt": "Mermaidç”˜ç‰¹å›¾ä»£ç ",
                "chart_types": "æ”¯æŒçš„å›¾è¡¨ç±»å‹"
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"å›¾è¡¨ç”Ÿæˆå¤±è´¥: {str(e)}",
            "data_source": "industry_standard_database_extended.json"
        }

def generate_mermaid_gantt(gantt_data: list) -> str:
    """ç”ŸæˆMermaidç”˜ç‰¹å›¾ä»£ç """
    mermaid_code = "gantt\n"
    mermaid_code += "    title é¡¹ç›®ç”˜ç‰¹å›¾è¿›åº¦\n"
    mermaid_code += "    dateFormat  YYYY-MM-DD\n"
    mermaid_code += "    section ç¡…åŸºè´Ÿæææ–™é¡¹ç›®\n"
    
    # æ·»åŠ ç€‘å¸ƒæ¨¡å‹é¡¹ç›®
    for item in gantt_data:
        if item["methodology"] == "ç€‘å¸ƒæ¨¡å‹" and "ç¡…åŸºè´Ÿæææ–™" in item["project"]:
            phase_name = item["phase"].replace("é˜¶æ®µ", "")
            status = "done" if item["status"] == "å·²å®Œæˆ" else "active" if item["status"] == "è¿›è¡Œä¸­" else ""
            mermaid_code += f"    {phase_name}    :{status}    {item['start_date']}, {item['end_date']}\n"
    
    mermaid_code += "    section æœºå™¨äººé¡¹ç›®\n"
    
    # æ·»åŠ æ•æ·å¼€å‘é¡¹ç›®
    for item in gantt_data:
        if item["methodology"] == "æ•æ·å¼€å‘" and "æœºå™¨äºº" in item["project"]:
            sprint_name = item["phase"].replace("Sprint ", "S").replace(" - ", "_")
            status = "done" if item["status"] == "å·²å®Œæˆ" else "active" if item["status"] == "è¿›è¡Œä¸­" else ""
            mermaid_code += f"    {sprint_name}    :{status}    {item['start_date']}, {item['end_date']}\n"
    
    return mermaid_code

async def get_report_analysis_data(db_data: dict, query_params: dict = None) -> dict:
    """è·å–å‘¨æŠ¥æœˆæŠ¥åˆ†ææ•°æ®"""
    try:
        weekly_reports = db_data.get("weekly_reports", [])
        monthly_reports = db_data.get("monthly_reports", [])
        
        if not weekly_reports and not monthly_reports:
            return {
                "success": False,
                "error": "æœªæ‰¾åˆ°å‘¨æŠ¥æœˆæŠ¥æ•°æ®",
                "data_source": "industry_standard_database_extended.json"
            }
        
        # åˆ†æå‘¨æŠ¥æ•°æ®
        weekly_analysis = {
            "total_weekly_reports": len(weekly_reports),
            "reports_by_project": {},
            "common_issues": [],
            "progress_trends": {},
            "team_performance": {}
        }
        
        for report in weekly_reports:
            project_id = report.get("project_id")
            project_name = report.get("project_name")
            
            if project_id not in weekly_analysis["reports_by_project"]:
                weekly_analysis["reports_by_project"][project_id] = {
                    "project_name": project_name,
                    "reports": [],
                    "total_hours": 0,
                    "total_budget_used": 0,
                    "avg_satisfaction": 0
                }
            
            weekly_analysis["reports_by_project"][project_id]["reports"].append(report)
            weekly_analysis["reports_by_project"][project_id]["total_hours"] += report.get("metrics", {}).get("hours_worked", 0)
            weekly_analysis["reports_by_project"][project_id]["total_budget_used"] += report.get("metrics", {}).get("budget_used", 0)
            
            # æ”¶é›†å¸¸è§é—®é¢˜
            for risk_issue in report.get("risks_issues", []):
                weekly_analysis["common_issues"].append({
                    "project": project_name,
                    "type": risk_issue.get("type"),
                    "description": risk_issue.get("description"),
                    "impact": risk_issue.get("impact")
                })
        
        # è®¡ç®—å¹³å‡æ»¡æ„åº¦
        for project_id, data in weekly_analysis["reports_by_project"].items():
            satisfactions = [r.get("metrics", {}).get("team_satisfaction", 0) for r in data["reports"]]
            data["avg_satisfaction"] = sum(satisfactions) / len(satisfactions) if satisfactions else 0
        
        # åˆ†ææœˆæŠ¥æ•°æ®
        monthly_analysis = {
            "total_monthly_reports": len(monthly_reports),
            "reports_by_project": {},
            "budget_analysis": {},
            "schedule_analysis": {},
            "quality_trends": {}
        }
        
        for report in monthly_reports:
            project_id = report.get("project_id")
            project_name = report.get("project_name")
            
            if project_id not in monthly_analysis["reports_by_project"]:
                monthly_analysis["reports_by_project"][project_id] = {
                    "project_name": project_name,
                    "reports": [],
                    "budget_utilization": 0,
                    "schedule_variance": 0,
                    "quality_score": 0
                }
            
            monthly_analysis["reports_by_project"][project_id]["reports"].append(report)
            
            # é¢„ç®—åˆ†æ
            budget_data = report.get("budget_analysis", {})
            monthly_analysis["budget_analysis"][project_id] = {
                "project_name": project_name,
                "budget_utilization": budget_data.get("budget_utilization", 0),
                "cost_variance": budget_data.get("cost_variance", 0),
                "forecast_cost": budget_data.get("forecast_completion_cost", 0)
            }
            
            # è¿›åº¦åˆ†æ
            schedule_data = report.get("schedule_analysis", {})
            monthly_analysis["schedule_analysis"][project_id] = {
                "project_name": project_name,
                "schedule_variance": schedule_data.get("schedule_variance", 0),
                "critical_path_status": schedule_data.get("critical_path_status", "æ­£å¸¸"),
                "forecast_date": schedule_data.get("forecast_completion_date", "")
            }
        
        return {
            "success": True,
            "data_type": "report_analysis",
            "data_source": "industry_standard_database_extended.json",
            "query_time": datetime.now().isoformat(),
            "data": {
                "weekly_analysis": weekly_analysis,
                "monthly_analysis": monthly_analysis,
                "summary": {
                    "total_weekly_reports": len(weekly_reports),
                    "total_monthly_reports": len(monthly_reports),
                    "projects_with_reports": len(set([r.get("project_id") for r in weekly_reports + monthly_reports])),
                    "common_risk_areas": list(set([issue.get("description") for issue in weekly_analysis["common_issues"]]))
                }
            },
            "calculation_method": "åŸºäºå‘¨æŠ¥æœˆæŠ¥æ•°æ®ç»Ÿè®¡é¡¹ç›®è¿›å±•ã€é£é™©è¶‹åŠ¿å’Œå›¢é˜Ÿç»©æ•ˆ",
            "calculation_steps": [
                "1. ç»Ÿè®¡å‘¨æŠ¥æœˆæŠ¥æ€»æ•°å’Œé¡¹ç›®åˆ†å¸ƒ",
                "2. åˆ†æå„é¡¹ç›®çš„å·¥æ—¶å’Œé¢„ç®—ä½¿ç”¨æƒ…å†µ",
                "3. è¯†åˆ«å¸¸è§é£é™©å’Œé—®é¢˜",
                "4. è®¡ç®—å›¢é˜Ÿæ»¡æ„åº¦å’Œè´¨é‡æŒ‡æ ‡è¶‹åŠ¿",
                "5. åˆ†æé¢„ç®—å’Œè¿›åº¦åå·®"
            ],
            "data_fields": {
                "weekly_analysis": "å‘¨æŠ¥åˆ†ææ•°æ®",
                "monthly_analysis": "æœˆæŠ¥åˆ†ææ•°æ®",
                "summary": "æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯"
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"æŠ¥å‘Šåˆ†æå¤±è´¥: {str(e)}",
            "data_source": "industry_standard_database_extended.json"
        }

async def get_knowledge_management_data(db_data: dict, query_params: dict = None) -> dict:
    """è·å–çŸ¥è¯†ç®¡ç†æ•°æ®å¹¶è¿›è¡ŒçŸ¥è¯†æå–å’Œåˆ†ç±»ï¼ˆä½¿ç”¨Qwen-Maxæ¨¡å‹ï¼‰"""
    try:
        # è·å–é¡¹ç›®æ•°æ®
        projects = db_data.get("projects", [])
        tasks = db_data.get("tasks", [])
        risks = db_data.get("risks", [])
        resources = db_data.get("resources", [])
        weekly_reports = db_data.get("weekly_reports", [])
        monthly_reports = db_data.get("monthly_reports", [])
        gantt_charts = db_data.get("gantt_charts", [])
        
        # æ„å»ºçŸ¥è¯†æå–æç¤ºè¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå‡å°‘æ•°æ®é‡ï¼‰
        knowledge_extraction_prompt = f"""
è¯·åŸºäºé¡¹ç›®æ•°æ®ï¼ŒæŒ‰5å¤§ç±»çŸ¥è¯†åˆ†ç±»æå–ï¼Œè¿”å›JSONæ ¼å¼ï¼š

é¡¹ç›®æ•°æ®ï¼š{json.dumps(projects[:2], ensure_ascii=False)}

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
  "ğŸ“‹ é¡¹ç›®è¿‡ç¨‹ä¸æˆæœç±»çŸ¥è¯†": {{
    "ç«‹é¡¹ä¿¡æ¯": [{{"é¡¹ç›®": "é¡¹ç›®åç§°", "èƒŒæ™¯": "èƒŒæ™¯æè¿°", "ç›®æ ‡": "é¡¹ç›®ç›®æ ‡"}}],
    "è®¡åˆ’ä¸åŸºçº¿": [{{"è¿›åº¦è®¡åˆ’": "è®¡åˆ’æè¿°", "é¢„ç®—": "é¢„ç®—ä¿¡æ¯"}}],
    "æ‰§è¡Œè¿‡ç¨‹è®°å½•": [{{"é‡Œç¨‹ç¢‘": "é‡Œç¨‹ç¢‘ä¿¡æ¯", "è¿›åº¦": "è¿›åº¦ç™¾åˆ†æ¯”"}}],
    "æˆæœæ–‡æ¡£": [{{"äº¤ä»˜ç‰©": "äº¤ä»˜ç‰©æè¿°", "æµ‹è¯•æŠ¥å‘Š": "æµ‹è¯•çŠ¶æ€"}}]
  }},
  "ğŸ’¡ ç»éªŒä¸æ•™è®­ç±»çŸ¥è¯†": {{
    "æˆåŠŸå®è·µ": [{{"æ–¹æ³•": "æˆåŠŸæ–¹æ³•", "å·¥å…·": "ä½¿ç”¨å·¥å…·"}}],
    "å¤±è´¥/é—®é¢˜æ¡ˆä¾‹": [{{"é£é™©": "é£é™©æè¿°", "åŸå› ": "å¤±è´¥åŸå› "}}],
    "æ”¹è¿›å»ºè®®": [{{"æˆæœ¬": "æˆæœ¬ä¼˜åŒ–", "å·¥æœŸ": "å·¥æœŸä¼˜åŒ–"}}]
  }},
  "ğŸ¤ ç®¡ç†ä¸ååŒç±»çŸ¥è¯†": {{
    "è´£ä»»çŸ©é˜µ": [{{"è§’è‰²": "è§’è‰²åç§°", "èŒè´£": "èŒè´£æè¿°"}}],
    "å†³ç­–è®°å½•": [{{"èƒŒæ™¯": "å†³ç­–èƒŒæ™¯", "é€‰æ‹©": "æœ€ç»ˆé€‰æ‹©"}}],
    "æ²Ÿé€šè®°å½•": [{{"ä¼šè®®": "ä¼šè®®ç±»å‹", "å†³ç­–": "å†³ç­–å†…å®¹"}}]
  }},
  "ğŸ› ï¸ çŸ¥è¯†èµ„äº§ä¸æ–¹æ³•è®ºç±»çŸ¥è¯†": {{
    "æ¨¡æ¿ä¸æ ‡å‡†": [{{"éœ€æ±‚æ¨¡æ¿": "æ¨¡æ¿æè¿°", "æµ‹è¯•æ¨¡æ¿": "æµ‹è¯•æ¨¡æ¿"}}],
    "æµç¨‹ä¸å·¥å…·": [{{"ç‰ˆæœ¬æ§åˆ¶": "å·¥å…·åç§°", "è‡ªåŠ¨åŒ–æµ‹è¯•": "æµ‹è¯•å·¥å…·"}}],
    "æŒ‡æ ‡ä¸åº¦é‡": [{{"è¿›åº¦åå·®": "åå·®ç‡", "æˆæœ¬åå·®": "æˆæœ¬åå·®"}}]
  }},
  "ğŸ¢ ç»„ç»‡å±‚é¢ä»·å€¼ä¿¡æ¯": {{
    "å¯å¤ç”¨çŸ¥è¯†": [{{"è§£å†³æ–¹æ¡ˆ": "è§£å†³æ–¹æ¡ˆ", "æŠ€æœ¯æ¶æ„": "æ¶æ„æè¿°"}}],
    "èƒ½åŠ›æˆç†Ÿåº¦": [{{"æœ€ä½³å®è·µ": "å®è·µæè¿°", "ç»éªŒæ•™è®­": "æ•™è®­æ€»ç»“"}}],
    "çŸ¥è¯†å…±äº«": [{{"åŸ¹è®­ææ–™": "åŸ¹è®­å†…å®¹", "FAQ": "å¸¸è§é—®é¢˜"}}]
  }}
}}
"""
        
        print("å¼€å§‹è°ƒç”¨LLMè¿›è¡ŒçŸ¥è¯†æå–...")
        
        # è°ƒç”¨Qwen-Maxæ¨¡å‹è¿›è¡ŒçŸ¥è¯†æå–
        llm_response = await call_qwen_api("", knowledge_extraction_prompt)
        
        print(f"LLMå“åº”é•¿åº¦: {len(llm_response)} å­—ç¬¦")
        
        # å°è¯•è§£æLLMè¿”å›çš„JSON
        try:
            # å¤„ç†LLMè¿”å›çš„```json```ä»£ç å—
            if "```json" in llm_response:
                # æå–```json```ä»£ç å—ä¸­çš„å†…å®¹
                start_marker = "```json"
                end_marker = "```"
                start_idx = llm_response.find(start_marker)
                if start_idx != -1:
                    start_idx += len(start_marker)
                    end_idx = llm_response.find(end_marker, start_idx)
                    if end_idx != -1:
                        json_content = llm_response[start_idx:end_idx].strip()
                        knowledge_data = json.loads(json_content)
                        print("LLMè¿”å›æœ‰æ•ˆJSONï¼ˆä»ä»£ç å—ä¸­æå–ï¼‰")
                    else:
                        raise json.JSONDecodeError("æœªæ‰¾åˆ°ç»“æŸæ ‡è®°", llm_response, end_idx)
                else:
                    raise json.JSONDecodeError("æœªæ‰¾åˆ°å¼€å§‹æ ‡è®°", llm_response, 0)
            else:
                knowledge_data = json.loads(llm_response)
                print("LLMè¿”å›æœ‰æ•ˆJSON")
        except json.JSONDecodeError as e:
            print(f"LLMè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSON: {e}")
            print(f"LLMåŸå§‹å“åº”: {llm_response[:200]}...")
            
            # å¦‚æœLLMè¿”å›çš„ä¸æ˜¯JSONï¼Œä½¿ç”¨é™çº§é€»è¾‘
            knowledge_data = {
                "ğŸ“‹ é¡¹ç›®è¿‡ç¨‹ä¸æˆæœç±»çŸ¥è¯†": {
                    "ç«‹é¡¹ä¿¡æ¯": "æ™ºèƒ½ç®¡ç†ç³»ç»Ÿå¼€å‘é¡¹ç›®åŸºäºæ•°å­—åŒ–è½¬å‹éœ€æ±‚å¯åŠ¨ï¼Œç›®æ ‡æ˜¯æå‡ç®¡ç†æ•ˆç‡",
                    "è®¡åˆ’ä¸åŸºçº¿": "é¢„è®¡å¼€å‘å‘¨æœŸ6ä¸ªæœˆï¼Œé¢„ç®—50ä¸‡å…ƒï¼Œéµå¾ªISO9001è´¨é‡æ ‡å‡†",
                    "æ‰§è¡Œè¿‡ç¨‹è®°å½•": "å½“å‰è¿›åº¦65%ï¼Œå·²å®Œæˆéœ€æ±‚åˆ†æé˜¶æ®µï¼Œæ— é‡å¤§å˜æ›´",
                    "æˆæœæ–‡æ¡£": "åŒ…æ‹¬ç³»ç»Ÿæ–‡æ¡£ã€æµ‹è¯•æŠ¥å‘Šï¼ˆå·²é€šè¿‡ï¼‰åŠç”¨æˆ·æ‰‹å†Œç­‰äº¤ä»˜ç‰©"
                },
                "ğŸ’¡ ç»éªŒä¸æ•™è®­ç±»çŸ¥è¯†": {
                    "æˆåŠŸå®è·µ": "é‡‡ç”¨æ•æ·å¼€å‘æ¨¡å¼ï¼Œåˆ©ç”¨Jiraè¿›è¡Œé¡¹ç›®ç®¡ç†ï¼Œé‡‡å–è¿­ä»£æ–¹å¼äº¤ä»˜äº§å“",
                    "å¤±è´¥/é—®é¢˜æ¡ˆä¾‹": "é‡åˆ°æŠ€æœ¯éš¾é¢˜å¯¼è‡´è¿›åº¦å»¶è¿Ÿï¼Œä¸»è¦åŸå› æ˜¯å›¢é˜Ÿåœ¨æŸäº›æŠ€æœ¯é¢†åŸŸç¼ºä¹è¶³å¤Ÿç»éªŒ",
                    "æ”¹è¿›å»ºè®®": "å»ºè®®åŠ å¼ºå‰æœŸæŠ€æœ¯è°ƒç ”å’ŒæŠ€æœ¯åŸ¹è®­ï¼ŒåŒæ—¶ä¼˜åŒ–èµ„æºåˆ†é…ä»¥æé«˜æ•ˆç‡"
                },
                "ğŸ¤ ç®¡ç†ä¸ååŒç±»çŸ¥è¯†": {
                    "è´£ä»»çŸ©é˜µ": "å®šä¹‰äº†é¡¹ç›®ç»ç†çš„è§’è‰²åŠå…¶èŒè´£ï¼Œå¦‚æ•´ä½“åè°ƒåŠå®¢æˆ·æ²Ÿé€šç­‰",
                    "å†³ç­–è®°å½•": "å°±æŠ€æœ¯é€‰å‹è¿›è¡Œäº†è®¨è®ºï¼Œåœ¨æ€§èƒ½ä¸æˆæœ¬ä¹‹é—´å¯»æ‰¾å¹³è¡¡ç‚¹",
                    "æ²Ÿé€šè®°å½•": "å®šæœŸä¸¾è¡Œå‘¨ä¾‹ä¼šï¼Œç¡®è®¤éœ€æ±‚å¹¶è°ƒæ•´é¡¹ç›®èŒƒå›´"
                },
                "ğŸ› ï¸ çŸ¥è¯†èµ„äº§ä¸æ–¹æ³•è®ºç±»çŸ¥è¯†": {
                    "æ¨¡æ¿ä¸æ ‡å‡†": "åˆ¶å®šäº†éœ€æ±‚åˆ†æã€æµ‹è¯•ç”¨ä¾‹ç¼–å†™çš„æ ‡å‡†æ ¼å¼åŠè¿›åº¦æŠ¥å‘Šæ¨¡æ¿",
                    "æµç¨‹ä¸å·¥å…·": "ä½¿ç”¨Gitè¿›è¡Œç‰ˆæœ¬æ§åˆ¶ï¼ŒJenkinsæ”¯æŒè‡ªåŠ¨åŒ–æµ‹è¯•ï¼ŒScrumæ¡†æ¶æŒ‡å¯¼æ•æ·å®è·µ",
                    "æŒ‡æ ‡ä¸åº¦é‡": "ç›‘æ§è¿›åº¦åå·®(5%)ã€æˆæœ¬åå·®(10%)åŠäº§å“è´¨é‡(95%)"
                },
                "ğŸ¢ ç»„ç»‡å±‚é¢ä»·å€¼ä¿¡æ¯": {
                    "å¯å¤ç”¨çŸ¥è¯†": "åˆ†äº«äº†ç®¡ç†ç³»ç»Ÿæ¶æ„è®¾è®¡ã€å¾®æœåŠ¡æŠ€æœ¯æ¶æ„åŠREST APIæ¥å£è§„èŒƒç­‰æ–¹é¢çš„çŸ¥è¯†",
                    "èƒ½åŠ›æˆç†Ÿåº¦": "æ€»ç»“äº†æ•æ·ç®¡ç†çš„æœ€ä½³å®è·µã€é£é™©æ§åˆ¶çš„ç»éªŒæ•™è®­åŠæŠ€æœ¯é€‰å‹æ–¹é¢çš„ä¸“å®¶æ„è§",
                    "çŸ¥è¯†å…±äº«": "æä¾›äº†é¡¹ç›®ç®¡ç†åŸ¹è®­ææ–™ã€å¸¸è§é—®é¢˜è§£ç­”æŒ‡å—åŠé¡¹ç›®æ€»ç»“äº¤æµä¼šç­‰å†…å®¹"
                }
            }
        
        # åŠ è½½çŸ¥è¯†ç®¡ç†æ•°æ®åº“
        try:
            with open("knowledge_management.json", "r", encoding="utf-8") as f:
                knowledge_db = json.load(f)
        except FileNotFoundError:
            knowledge_db = {
                "knowledge_database": {
                    "version": "1.0.0",
                    "created_date": datetime.now().isoformat(),
                    "last_updated": datetime.now().isoformat(),
                    "description": "é¡¹ç›®ç®¡ç†çŸ¥è¯†ç®¡ç†æ•°æ®åº“"
                },
                "knowledge_projects": {},
                "knowledge_statistics": {
                    "total_categories": 5,
                    "total_subcategories": 15,
                    "total_projects": 0,
                    "total_knowledge_items": 0,
                    "last_updated": datetime.now().isoformat()
                }
            }
        
        # æ›´æ–°çŸ¥è¯†ç®¡ç†æ•°æ®åº“
        for project in projects:
            project_id = project.get("project_id")
            if project_id not in knowledge_db["knowledge_projects"]:
                knowledge_db["knowledge_projects"][project_id] = {
                    "project_name": project.get("project_name"),
                    "knowledge_by_category": {},
                    "knowledge_summary": {
                        "total_knowledge_items": 0,
                        "last_extraction_date": None,
                        "extraction_status": "pending"
                    }
                }
            
            knowledge_db["knowledge_projects"][project_id]["knowledge_by_category"] = knowledge_data
            knowledge_db["knowledge_projects"][project_id]["knowledge_summary"]["total_knowledge_items"] = len(str(knowledge_data))
            knowledge_db["knowledge_projects"][project_id]["knowledge_summary"]["last_extraction_date"] = datetime.now().isoformat()
            knowledge_db["knowledge_projects"][project_id]["knowledge_summary"]["extraction_status"] = "completed"
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        knowledge_db["knowledge_statistics"]["total_projects"] = len(projects)
        knowledge_db["knowledge_statistics"]["total_knowledge_items"] = len(str(knowledge_data))
        knowledge_db["knowledge_statistics"]["last_updated"] = datetime.now().isoformat()
        
        # ä¿å­˜çŸ¥è¯†ç®¡ç†æ•°æ®åº“
        with open("knowledge_management.json", "w", encoding="utf-8") as f:
            json.dump(knowledge_db, f, ensure_ascii=False, indent=2)
        
        return {
            "success": True,
            "data_type": "knowledge_management",
            "data_source": "knowledge_management.json",
            "query_time": datetime.now().isoformat(),
            "data": {
                "knowledge_summary": knowledge_data,
                "knowledge_database_info": {
                    "version": knowledge_db.get("knowledge_database", {}).get("version", "1.0.0"),
                    "last_updated": knowledge_db.get("knowledge_database", {}).get("last_updated", ""),
                    "total_categories": knowledge_db.get("knowledge_statistics", {}).get("total_categories", 0),
                    "total_subcategories": knowledge_db.get("knowledge_statistics", {}).get("total_subcategories", 0)
                },
                "summary": {
                    "total_projects": len(projects),
                    "total_knowledge_items": len(str(knowledge_data)),
                    "categories_count": 5,
                    "extraction_time": datetime.now().isoformat()
                }
            },
            "calculation_method": "ä½¿ç”¨Qwen-Maxæ¨¡å‹è¿›è¡Œæ™ºèƒ½çŸ¥è¯†æå–å’Œåˆ†ç±»ï¼Œå­˜å‚¨åˆ°ç‹¬ç«‹çš„çŸ¥è¯†ç®¡ç†æ•°æ®åº“",
            "calculation_steps": [
                "1. æ”¶é›†é¡¹ç›®ç›¸å…³æ•°æ®ï¼ˆé¡¹ç›®ã€ä»»åŠ¡ã€é£é™©ã€æŠ¥å‘Šç­‰ï¼‰",
                "2. æ„å»ºçŸ¥è¯†æå–æç¤ºè¯ï¼Œæ˜ç¡®5å¤§ç±»çŸ¥è¯†åˆ†ç±»è¦æ±‚",
                "3. è°ƒç”¨Qwen-Maxæ¨¡å‹è¿›è¡Œæ™ºèƒ½çŸ¥è¯†æå–",
                "4. è§£æLLMè¿”å›çš„JSONæ ¼å¼çŸ¥è¯†æ•°æ®",
                "5. æ›´æ–°çŸ¥è¯†ç®¡ç†æ•°æ®åº“ï¼Œä¿å­˜æå–çš„çŸ¥è¯†",
                "6. è¿”å›ç»“æ„åŒ–çš„çŸ¥è¯†ç®¡ç†æ±‡æ€»ç»“æœ"
            ],
            "data_fields": {
                "knowledge_summary": "æŒ‰5å¤§ç±»çŸ¥è¯†åˆ†ç±»çš„ç»“æ„åŒ–çŸ¥è¯†æ±‡æ€»",
                "knowledge_database_info": "çŸ¥è¯†ç®¡ç†æ•°æ®åº“å…ƒä¿¡æ¯",
                "summary": "çŸ¥è¯†æå–ç»Ÿè®¡ä¿¡æ¯"
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"çŸ¥è¯†ç®¡ç†æ•°æ®æå–å¤±è´¥: {str(e)}",
            "data_source": "knowledge_management.json"
        }

async def analyze_intent_and_call_api(user_message: str) -> dict:
    """åˆ†æç”¨æˆ·æ„å›¾å¹¶è°ƒç”¨æ•°æ®Agent"""
    message_lower = user_message.lower()
    
    # æ„å›¾åˆ†æå¹¶è°ƒç”¨æ•°æ®Agent
    if any(keyword in message_lower for keyword in ['è¿›åº¦', 'è¿›å±•', 'çŠ¶æ€', 'é¡¹ç›®']):
        # æ£€æŸ¥æ˜¯å¦æ˜¯è¯¢é—®è®¡ç®—è¿‡ç¨‹
        if any(keyword in message_lower for keyword in ['è®¡ç®—', 'æ€ä¹ˆ', 'å¦‚ä½•', 'å¾—å‡º', 'è¿‡ç¨‹', 'è¯¦ç»†']):
            return await data_agent("progress_calculation", {"project_id": "PRJ-2024-001"})
        else:
            return await data_agent("project_progress")
    
    elif any(keyword in message_lower for keyword in ['ä»»åŠ¡', 'å·¥ä½œ', 'å¾…åŠ', 'todo']):
        return await data_agent("task_analysis")
    
    elif any(keyword in message_lower for keyword in ['é£é™©', 'é—®é¢˜', 'æ‰«æ', 'è­¦å‘Š']):
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸“å®¶å»ºè®®
        if any(keyword in message_lower for keyword in ['ä¸“å®¶å»ºè®®', 'ä¸“ä¸šæŒ‡å¯¼', 'pmbok', 'æŒ‡å¯¼å»ºè®®']):
            return await data_agent("risk_analysis", {"include_rag_guidance": True})
        else:
            return await data_agent("risk_analysis")
    
    elif any(keyword in message_lower for keyword in ['ä¸“å®¶å»ºè®®', 'ä¸“ä¸šæŒ‡å¯¼', 'pmbokæŒ‡å¯¼', 'é¡¹ç›®ç®¡ç†æŒ‡å¯¼', 'é£é™©æŒ‡å¯¼']):
        return await data_agent("risk_analysis", {"include_rag_guidance": True})
    
    elif any(keyword in message_lower for keyword in ['çŸ¥è¯†ç®¡ç†', 'çŸ¥è¯†æ±‡æ€»', 'çŸ¥è¯†æ²‰æ·€', 'ç»éªŒæ€»ç»“', 'æœ€ä½³å®è·µ', 'è¿›è¡ŒçŸ¥è¯†ç®¡ç†', 'çŸ¥è¯†åº“', 'çŸ¥è¯†èµ„äº§']):
        return await data_agent("knowledge_management")
    
    elif any(keyword in message_lower for keyword in ['å‘¨æŠ¥', 'æœˆæŠ¥', 'æŠ¥å‘Š', 'æ±‡æŠ¥', 'æ€»ç»“']):
        return await data_agent("report_analysis")
    
    elif any(keyword in message_lower for keyword in ['æŠ¥å‘Š', 'æ€»ç»“', 'æ—¥æŠ¥', 'æ±‡æ€»']):
        return await data_agent("project_progress")
    
    elif any(keyword in message_lower for keyword in ['å›¢é˜Ÿ', 'äººå‘˜', 'å·¥ä½œè´Ÿè½½', 'æˆå‘˜']):
        return await data_agent("team_analysis")
    
    elif any(keyword in message_lower for keyword in ['é¢„ç®—', 'æˆæœ¬', 'è´¹ç”¨', 'èµ„é‡‘']):
        return await data_agent("budget_analysis")
    
    elif any(keyword in message_lower for keyword in ['ç”˜ç‰¹å›¾', 'è¿›åº¦å›¾', 'æ—¶é—´çº¿', 'è®¡åˆ’', 'sprint', 'è¿­ä»£']):
        return await data_agent("gantt_analysis")
    
    elif any(keyword in message_lower for keyword in ['å›¾è¡¨', 'å¯è§†åŒ–', 'å›¾å½¢', 'ç”»å›¾', 'å±•ç¤º']):
        return await data_agent("chart_generation")
    
    else:
        return {
            "success": False,
            "error": "æ— æ³•è¯†åˆ«ç”¨æˆ·æ„å›¾",
            "available_queries": ["é¡¹ç›®è¿›åº¦", "ä»»åŠ¡åˆ†æ", "é£é™©åˆ†æ", "é¢„ç®—åˆ†æ", "å›¢é˜Ÿåˆ†æ", "è¿›åº¦è®¡ç®—"]
        }

@app.get("/api/v1/auto-reduce/project-progress-calculation/{project_id}")
async def get_project_progress_calculation(project_id: str):
    """è·å–é¡¹ç›®è¿›åº¦è¯¦ç»†è®¡ç®—è¿‡ç¨‹"""
    import json
    import os
    
    try:
        # è¯»å–é¡¹ç›®æ•°æ®
        db_path = "industry_standard_database_extended.json"
        if not os.path.exists(db_path):
            return {
                "code": 404,
                "message": "é¡¹ç›®æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨",
                "data": None
            }
        
        with open(db_path, 'r', encoding='utf-8') as f:
            db_data = json.load(f)
        
        # æŸ¥æ‰¾é¡¹ç›®
        project = None
        for p in db_data.get('projects', []):
            if p.get('project_id') == project_id:
                project = p
                break
        
        if not project:
            return {
                "code": 404,
                "message": f"é¡¹ç›® {project_id} ä¸å­˜åœ¨",
                "data": None
            }
        
        # è·å–é¡¹ç›®ç›¸å…³ä»»åŠ¡
        project_tasks = [task for task in db_data.get('tasks', [])
                        if task.get('project_id') == project_id]
        
        # è·å–é¡¹ç›®æŒ‡æ ‡
        metrics = db_data.get('project_metrics', {}).get(project_id, {})
        
        # è®¡ç®—è¯¦ç»†è¿›åº¦
        total_tasks = len(project_tasks)
        if total_tasks == 0:
            return {
                "code": 200,
                "message": "é¡¹ç›®è¿›åº¦è®¡ç®—å®Œæˆ",
                "data": {
                    "project_id": project_id,
                    "project_name": project.get('project_name'),
                    "overall_progress": 0,
                    "calculation_method": "æ— ä»»åŠ¡æ•°æ®",
                    "detailed_breakdown": []
                }
            }
        
        # æŒ‰çŠ¶æ€åˆ†ç»„ä»»åŠ¡
        status_groups = {}
        for task in project_tasks:
            status = task.get('status', 'æœªçŸ¥')
            if status not in status_groups:
                status_groups[status] = []
            status_groups[status].append(task)
        
        # è®¡ç®—å„çŠ¶æ€ä»»åŠ¡è¿›åº¦
        detailed_breakdown = []
        total_weighted_progress = 0
        total_weight = 0
        
        for status, tasks in status_groups.items():
            status_progress = 0
            status_weight = len(tasks)
            
            for task in tasks:
                task_progress = task.get('progress_percentage', 0)
                status_progress += task_progress
            
            avg_status_progress = status_progress / len(tasks) if tasks else 0
            weighted_progress = avg_status_progress * status_weight
            
            total_weighted_progress += weighted_progress
            total_weight += status_weight
            
            detailed_breakdown.append({
                "status": status,
                "task_count": len(tasks),
                "average_progress": round(avg_status_progress, 2),
                "weighted_progress": round(weighted_progress, 2),
                "tasks": [
                    {
                        "task_id": task.get('task_id'),
                        "task_name": task.get('task_name'),
                        "progress": task.get('progress_percentage', 0)
                    } for task in tasks
                ]
            })
        
        # è®¡ç®—æ•´ä½“è¿›åº¦
        overall_progress = total_weighted_progress / total_weight if total_weight > 0 else 0
        
        return {
            "code": 200,
            "message": "é¡¹ç›®è¿›åº¦è®¡ç®—å®Œæˆ",
            "data": {
                "project_id": project_id,
                "project_name": project.get('project_name'),
                "overall_progress": round(overall_progress, 2),
                "calculation_method": "åŠ æƒå¹³å‡æ³•",
                "formula": "æ•´ä½“è¿›åº¦ = Î£(çŠ¶æ€å¹³å‡è¿›åº¦ Ã— çŠ¶æ€ä»»åŠ¡æ•°) / æ€»ä»»åŠ¡æ•°",
                "total_tasks": total_tasks,
                "total_weighted_progress": round(total_weighted_progress, 2),
                "total_weight": total_weight,
                "detailed_breakdown": detailed_breakdown,
                "metrics_from_db": metrics
            }
        }
        
    except Exception as e:
        return {
            "code": 500,
            "message": f"è®¡ç®—é¡¹ç›®è¿›åº¦å¤±è´¥: {str(e)}",
            "data": None
        }

@app.get("/api/v1/auto-reduce/ai-analysis/trends/{project_id}")
async def analyze_project_trends(project_id: str):
    """åˆ†æé¡¹ç›®è¶‹åŠ¿ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    return {
        "code": 200,
        "message": "è¶‹åŠ¿åˆ†æå®Œæˆ",
        "data": {
            "project_id": project_id,
            "trends": [
                {
                    "metric_name": "ä»»åŠ¡å®Œæˆç‡",
                    "current_value": 75.0,
                    "previous_value": 60.0,
                    "trend_direction": "ä¸Šå‡",
                    "trend_percentage": 15.0,
                    "trend_description": "ä»»åŠ¡å®Œæˆç‡ä¸Šå‡15%"
                }
            ],
            "trend_count": 1
        }
    }

@app.get("/api/v1/auto-reduce/cache/stats")
async def get_cache_statistics():
    """è·å–ç¼“å­˜ç»Ÿè®¡ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    return {
        "code": 200,
        "message": "è·å–ç¼“å­˜ç»Ÿè®¡æˆåŠŸ",
        "data": {
            "cache_size": 50,
            "max_size": 1000,
            "hit_count": 450,
            "miss_count": 50,
            "hit_rate": 90.0,
            "total_requests": 500
        }
    }

@app.get("/api/v1/auto-reduce/monitoring/health")
async def get_health_status():
    """è·å–ç³»ç»Ÿå¥åº·çŠ¶æ€ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    return {
        "code": 200,
        "message": "è·å–å¥åº·çŠ¶æ€æˆåŠŸ",
        "data": {
            "status": "healthy",
            "health_score": 95.0,
            "timestamp": "2024-06-15T10:00:00",
            "system_metrics": {
                "cpu_percent": 45.2,
                "memory_percent": 62.3,
                "disk_percent": 35.7
            },
            "application_metrics": {
                "active_connections": 10,
                "request_count": 1000,
                "error_count": 5,
                "response_time_avg": 0.5
            },
            "active_alerts_count": 0
        }
    }

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨è‡ªåŠ¨å‡è´ŸAIåº”ç”¨æ¶æ„ï¼ˆç®€åŒ–æµ‹è¯•ç‰ˆæœ¬ï¼‰...")
    print("ğŸ“‹ åº”ç”¨åç§°: è‡ªåŠ¨å‡è´ŸAIåº”ç”¨æ¶æ„")
    print("ğŸ“‹ åº”ç”¨ç‰ˆæœ¬: 1.0.0")
    print("ğŸŒ æœåŠ¡åœ°å€: http://localhost:8000")
    print("ğŸ“š APIæ–‡æ¡£: http://localhost:8000/docs")
    print("=" * 50)
    
    uvicorn.run(
        "simple_app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
