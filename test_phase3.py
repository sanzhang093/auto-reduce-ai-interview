"""
ç¬¬ä¸‰é˜¶æ®µåŠŸèƒ½æµ‹è¯•è„šæœ¬
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.qwen_agent import qwen_agent_service
from app.services.rag_system import rag_system
from app.services.ai_analysis import ai_analysis_service
from app.utils.logger import get_logger

logger = get_logger(__name__)


def test_qwen_agent():
    """æµ‹è¯•é€šä¹‰åƒé—®AgentæœåŠ¡"""
    print("=== æµ‹è¯•é€šä¹‰åƒé—®AgentæœåŠ¡ ===")
    
    try:
        # æµ‹è¯•æ™ºèƒ½å¯¹è¯
        test_user_id = "test_user_001"
        test_message = "è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹é¡¹ç›®çš„æ•´ä½“æƒ…å†µ"
        test_project_id = "PRJ-2024-001"
        
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®é™…çš„é€šä¹‰åƒé—®APIå¯†é’¥æ‰èƒ½æ­£å¸¸å·¥ä½œ
        # åœ¨æµ‹è¯•ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬æ¨¡æ‹ŸAPIè°ƒç”¨
        print(f"æµ‹è¯•ç”¨æˆ· {test_user_id} å‘èµ·å¯¹è¯: {test_message}")
        
        # æ¨¡æ‹Ÿå¯¹è¯å“åº”
        mock_response = {
            "session_id": "session_test_001",
            "response": "æ ¹æ®é¡¹ç›®æ•°æ®åˆ†æï¼Œé¡¹ç›®æ•´ä½“è¿›å±•è‰¯å¥½ï¼Œå»ºè®®å…³æ³¨é«˜é£é™©ä»»åŠ¡ã€‚",
            "relevant_docs": [],
            "context": "é¡¹ç›®ä¸Šä¸‹æ–‡ä¿¡æ¯",
            "timestamp": "2024-06-15T10:00:00"
        }
        
        print(f"AIå›å¤: {mock_response['response']}")
        
        # æµ‹è¯•ä»»åŠ¡è¯·æ±‚å¤„ç†
        task_request = "åˆ›å»ºä¸€ä¸ªæ–°çš„å¼€å‘ä»»åŠ¡ï¼šå®ç°ç”¨æˆ·ç™»å½•åŠŸèƒ½"
        print(f"æµ‹è¯•ä»»åŠ¡è¯·æ±‚: {task_request}")
        
        # æ¨¡æ‹Ÿä»»åŠ¡åˆ›å»ºå“åº”
        mock_task_response = {
            "action": "task_created",
            "task": {
                "task_id": "TASK-20240615-001",
                "task_name": "å®ç°ç”¨æˆ·ç™»å½•åŠŸèƒ½",
                "status": "å¾…å¼€å§‹"
            },
            "message": "å·²æˆåŠŸåˆ›å»ºä»»åŠ¡: å®ç°ç”¨æˆ·ç™»å½•åŠŸèƒ½"
        }
        
        print(f"ä»»åŠ¡åˆ›å»ºç»“æœ: {mock_task_response['message']}")
        
        # æµ‹è¯•ä¼šè¯ç®¡ç†
        sessions = qwen_agent_service.get_user_sessions(test_user_id)
        print(f"ç”¨æˆ·ä¼šè¯æ•°é‡: {len(sessions)}")
        
        print("âœ… é€šä¹‰åƒé—®AgentæœåŠ¡æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ é€šä¹‰åƒé—®AgentæœåŠ¡æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_rag_system():
    """æµ‹è¯•RAGæ£€ç´¢ç³»ç»Ÿ"""
    print("\n=== æµ‹è¯•RAGæ£€ç´¢ç³»ç»Ÿ ===")
    
    try:
        # æµ‹è¯•æ–‡æ¡£ç´¢å¼•
        test_project_id = "PRJ-2024-001"
        indexed_count = rag_system.index_project_data(test_project_id)
        print(f"é¡¹ç›®æ•°æ®ç´¢å¼•å®Œæˆï¼Œå…±ç´¢å¼• {indexed_count} ä¸ªæ–‡æ¡£")
        
        # æµ‹è¯•æ–‡æ¡£æœç´¢
        search_query = "é¡¹ç›®è¿›åº¦åˆ†æ"
        search_results = rag_system.search_documents(
            query=search_query,
            project_id=test_project_id,
            top_k=3
        )
        
        print(f"æœç´¢æŸ¥è¯¢: {search_query}")
        print(f"æœç´¢ç»“æœæ•°é‡: {len(search_results)}")
        
        for i, result in enumerate(search_results[:2], 1):
            print(f"  ç»“æœ {i}: {result.title} (ç›¸å…³æ€§: {result.relevance_score:.2f})")
        
        # æµ‹è¯•æ–‡æ¡£è·å–
        if search_results:
            doc_id = search_results[0].doc_id
            document = rag_system.get_document(doc_id)
            if document:
                print(f"è·å–æ–‡æ¡£: {document.title}")
        
        # æµ‹è¯•ç³»ç»Ÿç»Ÿè®¡
        statistics = rag_system.get_system_statistics()
        print(f"RAGç³»ç»Ÿç»Ÿè®¡: æ€»æ–‡æ¡£æ•° {statistics.get('total_documents', 0)}")
        
        print("âœ… RAGæ£€ç´¢ç³»ç»Ÿæµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ RAGæ£€ç´¢ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_ai_analysis():
    """æµ‹è¯•æ™ºèƒ½åˆ†æåŠŸèƒ½"""
    print("\n=== æµ‹è¯•æ™ºèƒ½åˆ†æåŠŸèƒ½ ===")
    
    try:
        test_project_id = "PRJ-2024-001"
        
        # æµ‹è¯•è¶‹åŠ¿åˆ†æ
        trends = ai_analysis_service.analyze_project_trends(test_project_id)
        print(f"è¶‹åŠ¿åˆ†æå®Œæˆï¼Œå…±åˆ†æ {len(trends)} ä¸ªè¶‹åŠ¿")
        
        for trend in trends[:2]:
            print(f"  - {trend.metric_name}: {trend.trend_description}")
        
        # æµ‹è¯•é¡¹ç›®æ´å¯Ÿ
        insights = ai_analysis_service.generate_project_insights(test_project_id)
        print(f"é¡¹ç›®æ´å¯Ÿç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(insights)} ä¸ªæ´å¯Ÿ")
        
        for insight in insights[:2]:
            print(f"  - {insight.title}: {insight.description}")
        
        # æµ‹è¯•AIå»ºè®®
        recommendations = ai_analysis_service.generate_ai_recommendations(test_project_id)
        print(f"AIå»ºè®®ç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(recommendations)} ä¸ªå»ºè®®")
        
        for rec in recommendations[:2]:
            print(f"  - {rec.title}: {rec.description}")
        
        # æµ‹è¯•ç»¼åˆåˆ†æ
        comprehensive_analysis = ai_analysis_service.generate_comprehensive_analysis(test_project_id)
        print(f"ç»¼åˆåˆ†æå®Œæˆï¼Œç»¼åˆè¯„åˆ†: {comprehensive_analysis.get('overall_score', 0):.1f}")
        
        print("âœ… æ™ºèƒ½åˆ†æåŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ æ™ºèƒ½åˆ†æåŠŸèƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_integration():
    """æµ‹è¯•é›†æˆåŠŸèƒ½"""
    print("\n=== æµ‹è¯•é›†æˆåŠŸèƒ½ ===")
    
    try:
        test_project_id = "PRJ-2024-001"
        test_user_id = "test_user_001"
        
        # æµ‹è¯•RAG + AIå¯¹è¯é›†æˆ
        print("æµ‹è¯•RAG + AIå¯¹è¯é›†æˆ...")
        
        # 1. ç´¢å¼•é¡¹ç›®æ•°æ®
        indexed_count = rag_system.index_project_data(test_project_id)
        print(f"  1. é¡¹ç›®æ•°æ®ç´¢å¼•: {indexed_count} ä¸ªæ–‡æ¡£")
        
        # 2. æœç´¢ç›¸å…³æ–‡æ¡£
        search_results = rag_system.search_documents(
            query="é¡¹ç›®é£é™©åˆ†æ",
            project_id=test_project_id,
            top_k=3
        )
        print(f"  2. æ–‡æ¡£æœç´¢: æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³æ–‡æ¡£")
        
        # 3. æ¨¡æ‹ŸAIå¯¹è¯ï¼ˆä½¿ç”¨æœç´¢åˆ°çš„æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡ï¼‰
        if search_results:
            context_docs = [f"- {result.title}: {result.content[:100]}..." for result in search_results]
            context = "ç›¸å…³é¡¹ç›®ä¿¡æ¯:\n" + "\n".join(context_docs)
            print(f"  3. æ„å»ºä¸Šä¸‹æ–‡: {len(context_docs)} ä¸ªæ–‡æ¡£")
        
        # 4. ç”Ÿæˆåˆ†ææŠ¥å‘Š
        analysis = ai_analysis_service.generate_comprehensive_analysis(test_project_id)
        print(f"  4. ç”Ÿæˆåˆ†ææŠ¥å‘Š: ç»¼åˆè¯„åˆ† {analysis.get('overall_score', 0):.1f}")
        
        # æµ‹è¯•æ™ºèƒ½å»ºè®®ç”Ÿæˆ
        print("æµ‹è¯•æ™ºèƒ½å»ºè®®ç”Ÿæˆ...")
        recommendations = ai_analysis_service.generate_ai_recommendations(test_project_id)
        high_priority_recs = [rec for rec in recommendations if rec.priority == "é«˜"]
        print(f"  é«˜ä¼˜å…ˆçº§å»ºè®®æ•°é‡: {len(high_priority_recs)}")
        
        print("âœ… é›†æˆåŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ é›†æˆåŠŸèƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç¬¬ä¸‰é˜¶æ®µåŠŸèƒ½æµ‹è¯•...")
    
    test_results = []
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    test_results.append(test_qwen_agent())
    test_results.append(test_rag_system())
    test_results.append(test_ai_analysis())
    test_results.append(test_integration())
    
    # ç»Ÿè®¡æµ‹è¯•ç»“æœ
    passed = sum(test_results)
    total = len(test_results)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ ç¬¬ä¸‰é˜¶æ®µåŠŸèƒ½æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

