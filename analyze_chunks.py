#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æRAGç³»ç»Ÿçš„chunkåˆ†å—æƒ…å†µ
"""

import json
import os
from typing import Dict, List
from collections import Counter

def analyze_chunks():
    """åˆ†æRAGç³»ç»Ÿçš„chunkåˆ†å—æƒ…å†µ"""
    print("ğŸ§© åˆ†æRAGç³»ç»Ÿchunkåˆ†å—æƒ…å†µ...")
    
    # æ„å»ºæ–‡ä»¶è·¯å¾„
    pmbok_dir = "PMBOKç¬¬ä¸ƒç‰ˆä¸­è‹±æ–‡èµ„æ–™"
    full_md_path = os.path.join(pmbok_dir, "0- PMBOKæŒ‡å— ç¬¬ä¸ƒç‰ˆ_ä¸­æ–‡ç‰ˆ.pdf-3bf8755e-73b1-4670-863e-8a3846f244be", "full.md")
    
    if not os.path.exists(full_md_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {full_md_path}")
        return
    
    # è¯»å–å®Œæ•´æ–‡æ¡£å†…å®¹
    with open(full_md_path, 'r', encoding='utf-8') as f:
        full_content = f.read()
    
    # æŒ‰ç« èŠ‚åˆ†å‰²å†…å®¹
    sections = split_pmbok_sections(full_content)
    
    # åˆ†æchunkç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š Chunkç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æ€»chunkæ•°é‡: {len(sections)}")
    
    # é•¿åº¦åˆ†æ
    lengths = [len(content) for content in sections.values()]
    lengths.sort()
    
    print(f"   æœ€çŸ­chunk: {min(lengths)} å­—ç¬¦")
    print(f"   æœ€é•¿chunk: {max(lengths)} å­—ç¬¦")
    print(f"   å¹³å‡é•¿åº¦: {sum(lengths)/len(lengths):.0f} å­—ç¬¦")
    print(f"   ä¸­ä½æ•°é•¿åº¦: {lengths[len(lengths)//2]} å­—ç¬¦")
    
    # é•¿åº¦åˆ†å¸ƒ
    print(f"\nğŸ“ˆ é•¿åº¦åˆ†å¸ƒ:")
    length_ranges = [
        (0, 500, "å¾ˆçŸ­"),
        (500, 1000, "çŸ­"),
        (1000, 2000, "ä¸­ç­‰"),
        (2000, 5000, "é•¿"),
        (5000, 8192, "å¾ˆé•¿"),
        (8192, float('inf'), "è¶…é•¿")
    ]
    
    for min_len, max_len, label in length_ranges:
        count = sum(1 for length in lengths if min_len <= length < max_len)
        percentage = count / len(lengths) * 100
        max_len_str = 'âˆ' if max_len == float('inf') else str(max_len)
        print(f"   {label:4s} ({min_len:4d}-{max_len_str:>4s}å­—ç¬¦): {count:3d}ä¸ª ({percentage:5.1f}%)")
    
    # è¶…é•¿chunkè¯¦æƒ…
    print(f"\nâš ï¸ è¶…é•¿chunkè¯¦æƒ… (>8192å­—ç¬¦):")
    long_chunks = [(name, len(content)) for name, content in sections.items() if len(content) > 8192]
    long_chunks.sort(key=lambda x: x[1], reverse=True)
    
    for name, length in long_chunks:
        print(f"   {name[:50]:<50} {length:>6}å­—ç¬¦ (è¶…å‡º{length-8192:>4}å­—ç¬¦)")
    
    # æœ€çŸ­chunkè¯¦æƒ…
    print(f"\nğŸ“ æœ€çŸ­chunkè¯¦æƒ… (<500å­—ç¬¦):")
    short_chunks = [(name, len(content)) for name, content in sections.items() if len(content) < 500]
    short_chunks.sort(key=lambda x: x[1])
    
    for name, length in short_chunks[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
        print(f"   {name[:50]:<50} {length:>6}å­—ç¬¦")
    
    # ç« èŠ‚ç±»å‹åˆ†æ
    print(f"\nğŸ“š ç« èŠ‚ç±»å‹åˆ†æ:")
    chapter_types = analyze_chapter_types(sections)
    for chapter_type, count in chapter_types.most_common():
        print(f"   {chapter_type:<20} {count:>3}ä¸ª")
    
    # é¡µç åˆ†å¸ƒ
    print(f"\nğŸ“„ é¡µç åˆ†å¸ƒåˆ†æ:")
    page_ranges = analyze_page_ranges(sections)
    for page_range, count in page_ranges.items():
        print(f"   {page_range:<15} {count:>3}ä¸ªchunk")
    
    # å†…å®¹è´¨é‡åˆ†æ
    print(f"\nğŸ” å†…å®¹è´¨é‡åˆ†æ:")
    quality_stats = analyze_content_quality(sections)
    print(f"   åŒ…å«è¡¨æ ¼çš„chunk: {quality_stats['has_tables']}ä¸ª")
    print(f"   åŒ…å«åˆ—è¡¨çš„chunk: {quality_stats['has_lists']}ä¸ª")
    print(f"   åŒ…å«ä»£ç çš„chunk: {quality_stats['has_code']}ä¸ª")
    print(f"   çº¯æ–‡æœ¬chunk: {quality_stats['plain_text']}ä¸ª")

def split_pmbok_sections(content: str) -> Dict[str, str]:
    """åˆ†å‰²PMBOKæ–‡æ¡£ä¸ºç« èŠ‚"""
    sections = {}
    current_section = "å‰è¨€"
    current_content = []
    
    lines = content.split('\n')
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # æ£€æµ‹ç« èŠ‚æ ‡é¢˜
        if line.startswith('# ') and len(line) > 2:
            # ä¿å­˜å‰ä¸€ç« èŠ‚
            if current_content:
                sections[current_section] = '\n'.join(current_content)
            
            # å¼€å§‹æ–°ç« èŠ‚
            current_section = line[2:].strip()
            current_content = [line]
        else:
            current_content.append(line)
    
    # ä¿å­˜æœ€åä¸€ç« èŠ‚
    if current_content:
        sections[current_section] = '\n'.join(current_content)
    
    return sections

def analyze_chapter_types(sections: Dict[str, str]) -> Counter:
    """åˆ†æç« èŠ‚ç±»å‹"""
    chapter_types = Counter()
    
    for section_name in sections.keys():
        if section_name.startswith('X'):
            chapter_types['é™„å½•'] += 1
        elif section_name.startswith('3.'):
            chapter_types['å®šä¹‰'] += 1
        elif section_name.startswith('4.'):
            chapter_types['æ–¹æ³•å·¥å…·'] += 1
        elif 'åŸåˆ™' in section_name:
            chapter_types['åŸåˆ™'] += 1
        elif 'ç»©æ•ˆåŸŸ' in section_name:
            chapter_types['ç»©æ•ˆåŸŸ'] += 1
        elif 'æ•æ·' in section_name or 'é€‚åº”' in section_name:
            chapter_types['æ•æ·ç®¡ç†'] += 1
        elif 'é£é™©' in section_name:
            chapter_types['é£é™©ç®¡ç†'] += 1
        elif 'å¹²ç³»äºº' in section_name:
            chapter_types['å¹²ç³»äººç®¡ç†'] += 1
        else:
            chapter_types['å…¶ä»–'] += 1
    
    return chapter_types

def analyze_page_ranges(sections: Dict[str, str]) -> Dict[str, int]:
    """åˆ†æé¡µç åˆ†å¸ƒ"""
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä»layout.jsonä¸­è·å–çœŸå®é¡µç 
    page_ranges = {
        "1-50é¡µ": 0,
        "51-100é¡µ": 0,
        "101-200é¡µ": 0,
        "201-300é¡µ": 0,
        "300é¡µä»¥ä¸Š": 0
    }
    
    # ç”±äºæ²¡æœ‰çœŸå®é¡µç ï¼Œè¿™é‡Œç”¨chunkç´¢å¼•æ¨¡æ‹Ÿ
    for i, (name, content) in enumerate(sections.items()):
        if i < 50:
            page_ranges["1-50é¡µ"] += 1
        elif i < 100:
            page_ranges["51-100é¡µ"] += 1
        elif i < 200:
            page_ranges["101-200é¡µ"] += 1
        elif i < 300:
            page_ranges["201-300é¡µ"] += 1
        else:
            page_ranges["300é¡µä»¥ä¸Š"] += 1
    
    return page_ranges

def analyze_content_quality(sections: Dict[str, str]) -> Dict[str, int]:
    """åˆ†æå†…å®¹è´¨é‡"""
    stats = {
        'has_tables': 0,
        'has_lists': 0,
        'has_code': 0,
        'plain_text': 0
    }
    
    for content in sections.values():
        if '<table>' in content or '|' in content:
            stats['has_tables'] += 1
        elif content.count('- ') > 3 or content.count('* ') > 3:
            stats['has_lists'] += 1
        elif '```' in content or '`' in content:
            stats['has_code'] += 1
        else:
            stats['plain_text'] += 1
    
    return stats

if __name__ == "__main__":
    try:
        analyze_chunks()
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
